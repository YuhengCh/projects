{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77352b18",
   "metadata": {},
   "source": [
    "Name:Yuheng Chen\n",
    "\n",
    "Github Username: YuhengCh\n",
    "\n",
    "USC ID: 9135161440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "bbe1f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d50db",
   "metadata": {},
   "source": [
    "## 1.Supervised, Semi-Supervised, and Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0bf0b3",
   "metadata": {},
   "source": [
    "#### a) Download the Breast Cancer Wisconsin (Diagnostic) Data Set which has IDs, classes (Benign=B, Malignant=M), and 30 attributes. This data has two output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676eb9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1      2      3       4       5        6        7        8   \\\n",
       "0      842302   1  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "1      842517   1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "2    84300903   1  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "3    84348301   1  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    84358402   1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..        ...  ..    ...    ...     ...     ...      ...      ...      ...   \n",
       "564    926424   1  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
       "565    926682   1  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
       "566    926954   1  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
       "567    927241   1  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
       "568     92751   0   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "          9   ...      22     23      24      25       26       27      28  \\\n",
       "0    0.14710  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         29      30       31  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/Homework_8_data/wdbc.data\", header=None)\n",
    "data.replace({'B' : 0, 'M' : 1}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fdeeb",
   "metadata": {},
   "source": [
    "#### (b) Monte-Carlo Simulation: Repeat the following procedures for supervised, unsupervised, and semi-supervised learning M= 30 times, and use randomly selected train and test data (make sure you use 20% of both the positve and negative classes as the test set). Then compare the average scores (accuracy, precision,recall,F1-score, and AUC) that you obtain from each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ec70a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426</td>\n",
       "      <td>0</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.047810</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8510653</td>\n",
       "      <td>0</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>0</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>854941</td>\n",
       "      <td>0</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>85713702</td>\n",
       "      <td>0</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>...</td>\n",
       "      <td>8.964</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>925277</td>\n",
       "      <td>0</td>\n",
       "      <td>14.590</td>\n",
       "      <td>22.68</td>\n",
       "      <td>96.39</td>\n",
       "      <td>657.1</td>\n",
       "      <td>0.08473</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.10290</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>...</td>\n",
       "      <td>15.480</td>\n",
       "      <td>27.27</td>\n",
       "      <td>105.90</td>\n",
       "      <td>733.5</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.31710</td>\n",
       "      <td>0.36620</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2258</td>\n",
       "      <td>0.08004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>925291</td>\n",
       "      <td>0</td>\n",
       "      <td>11.510</td>\n",
       "      <td>23.93</td>\n",
       "      <td>74.52</td>\n",
       "      <td>403.5</td>\n",
       "      <td>0.09261</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.041050</td>\n",
       "      <td>...</td>\n",
       "      <td>12.480</td>\n",
       "      <td>37.16</td>\n",
       "      <td>82.28</td>\n",
       "      <td>474.2</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.25170</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.09653</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.08732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>925292</td>\n",
       "      <td>0</td>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>925311</td>\n",
       "      <td>0</td>\n",
       "      <td>11.200</td>\n",
       "      <td>29.37</td>\n",
       "      <td>70.67</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.07449</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.920</td>\n",
       "      <td>38.30</td>\n",
       "      <td>75.19</td>\n",
       "      <td>439.6</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.05494</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>0.05905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.760</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1       2      3      4      5        6        7        8   \\\n",
       "19    8510426   0  13.540  14.36  87.46  566.3  0.09779  0.08129  0.06664   \n",
       "20    8510653   0  13.080  15.71  85.63  520.0  0.10750  0.12700  0.04568   \n",
       "21    8510824   0   9.504  12.44  60.34  273.9  0.10240  0.06492  0.02956   \n",
       "37     854941   0  13.030  18.42  82.61  523.8  0.08983  0.03766  0.02562   \n",
       "46   85713702   0   8.196  16.84  51.71  201.9  0.08600  0.05943  0.01588   \n",
       "..        ...  ..     ...    ...    ...    ...      ...      ...      ...   \n",
       "558    925277   0  14.590  22.68  96.39  657.1  0.08473  0.13300  0.10290   \n",
       "559    925291   0  11.510  23.93  74.52  403.5  0.09261  0.10210  0.11120   \n",
       "560    925292   0  14.050  27.15  91.38  600.4  0.09929  0.11260  0.04462   \n",
       "561    925311   0  11.200  29.37  70.67  386.0  0.07449  0.03558  0.00000   \n",
       "568     92751   0   7.760  24.54  47.92  181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "           9   ...      22     23      24     25       26       27       28  \\\n",
       "19   0.047810  ...  15.110  19.26   99.70  711.2  0.14400  0.17730  0.23900   \n",
       "20   0.031100  ...  14.500  20.49   96.09  630.5  0.13120  0.27760  0.18900   \n",
       "21   0.020760  ...  10.230  15.66   65.13  314.9  0.13240  0.11480  0.08867   \n",
       "37   0.029230  ...  13.300  22.81   84.46  545.9  0.09701  0.04619  0.04833   \n",
       "46   0.005917  ...   8.964  21.96   57.26  242.2  0.12970  0.13570  0.06880   \n",
       "..        ...  ...     ...    ...     ...    ...      ...      ...      ...   \n",
       "558  0.037360  ...  15.480  27.27  105.90  733.5  0.10260  0.31710  0.36620   \n",
       "559  0.041050  ...  12.480  37.16   82.28  474.2  0.12980  0.25170  0.36300   \n",
       "560  0.043040  ...  15.300  33.17  100.20  706.7  0.12410  0.22640  0.13260   \n",
       "561  0.000000  ...  11.920  38.30   75.19  439.6  0.09267  0.05494  0.00000   \n",
       "568  0.000000  ...   9.456  30.37   59.16  268.6  0.08996  0.06444  0.00000   \n",
       "\n",
       "          29      30       31  \n",
       "19   0.12880  0.2977  0.07259  \n",
       "20   0.07283  0.3184  0.08183  \n",
       "21   0.06227  0.2450  0.07773  \n",
       "37   0.05013  0.1987  0.06169  \n",
       "46   0.02564  0.3105  0.07409  \n",
       "..       ...     ...      ...  \n",
       "558  0.11050  0.2258  0.08004  \n",
       "559  0.09653  0.2112  0.08732  \n",
       "560  0.10480  0.2250  0.08321  \n",
       "561  0.00000  0.1566  0.05905  \n",
       "568  0.00000  0.2871  0.07039  \n",
       "\n",
       "[357 rows x 32 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data = data[data[1]==1]\n",
    "negative_data = data[data[1]==0]\n",
    "positive_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3acc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split 20% test data\n",
    "test_p = positive_data.sample(frac = 0.2, random_state = 42)\n",
    "test_n = negative_data.sample(frac = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "760ce402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>560</td>\n",
       "      <td>925292</td>\n",
       "      <td>0</td>\n",
       "      <td>14.05</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>...</td>\n",
       "      <td>15.300</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>562</td>\n",
       "      <td>925622</td>\n",
       "      <td>1</td>\n",
       "      <td>15.22</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "      <td>716.9</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>...</td>\n",
       "      <td>17.520</td>\n",
       "      <td>42.79</td>\n",
       "      <td>128.70</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.79170</td>\n",
       "      <td>1.1700</td>\n",
       "      <td>0.2356</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>0.14090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>564</td>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>567</td>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>568</td>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index         0  1      2      3       4       5        6        7  \\\n",
       "0        0    842302  1  17.99  10.38  122.80  1001.0  0.11840  0.27760   \n",
       "1        1    842517  1  20.57  17.77  132.90  1326.0  0.08474  0.07864   \n",
       "2        2  84300903  1  19.69  21.25  130.00  1203.0  0.10960  0.15990   \n",
       "3        3  84348301  1  11.42  20.38   77.58   386.1  0.14250  0.28390   \n",
       "4        4  84358402  1  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
       "..     ...       ... ..    ...    ...     ...     ...      ...      ...   \n",
       "451    560    925292  0  14.05  27.15   91.38   600.4  0.09929  0.11260   \n",
       "452    562    925622  1  15.22  30.62  103.40   716.9  0.10480  0.20870   \n",
       "453    564    926424  1  21.56  22.39  142.00  1479.0  0.11100  0.11590   \n",
       "454    567    927241  1  20.60  29.33  140.10  1265.0  0.11780  0.27700   \n",
       "455    568     92751  0   7.76  24.54   47.92   181.0  0.05263  0.04362   \n",
       "\n",
       "           8  ...      22     23      24      25       26       27      28  \\\n",
       "0    0.30010  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.08690  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.19740  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.24140  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.19800  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "451  0.04462  ...  15.300  33.17  100.20   706.7  0.12410  0.22640  0.1326   \n",
       "452  0.25500  ...  17.520  42.79  128.70   915.0  0.14170  0.79170  1.1700   \n",
       "453  0.24390  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "454  0.35140  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "455  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         29      30       31  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "451  0.1048  0.2250  0.08321  \n",
       "452  0.2356  0.4089  0.14090  \n",
       "453  0.2216  0.2060  0.07115  \n",
       "454  0.2650  0.4087  0.12400  \n",
       "455  0.0000  0.2871  0.07039  \n",
       "\n",
       "[456 rows x 33 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a function to get train and test dataset using index\n",
    "def index_get(whole_data, sample):\n",
    "    index_train = []\n",
    "    for x in whole_data.index:\n",
    "        if x not in sample.index:\n",
    "            index_train.append(x)\n",
    "    return index_train\n",
    "index_p = index_get(positive_data, test_p)\n",
    "index_n = index_get(negative_data, test_n)\n",
    "a = index_p + index_n\n",
    "b = [x for x in test_p.index] +[x for x in test_n.index]\n",
    "a.sort()\n",
    "b.sort()\n",
    "train = data.iloc[a].reset_index()\n",
    "test = data.iloc[b].reset_index()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a0d1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.iloc[:,3:], train[1]\n",
    "X_test, y_test = test.iloc[:,3:], test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "113eaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.iloc[:,2:], data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54665ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e01f251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce233fe",
   "metadata": {},
   "source": [
    "#### i.Supervised Learning:Train an L1-penalized SVM to classify the data.Use 5 fold cross validation to choose the penalty parameter. Use normalized data. Report the average accuracy, precision, recall,F1-score, and AUC, for both training and test sets over your M runs. Plot the ROC and report the confusion matrix for training and testing in one of the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a1c6f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "M = 30\n",
    "std_scal = StandardScaler()\n",
    "std_X = std_scal.fit_transform(X)\n",
    "std_X_train, std_X_test, y_train, y_test = train_test_split(std_X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6c262c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Supervised_learning(x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2, random_state = None)\n",
    "    c_range= [10**c for c in np.arange(-3,7, dtype=float)]\n",
    "    params = {'C':c_range}\n",
    "    Linear_SVC = LinearSVC(penalty = 'l1', dual=False, random_state = 42)\n",
    "    clf = GridSearchCV(Linear_SVC, params, cv=5)\n",
    "    clf.fit(x_train, y_train)\n",
    "    best_C = clf.best_params_['C']\n",
    "    \n",
    "    print('best c is:' ,best_C)\n",
    "    \n",
    "    #build l1svm with best c\n",
    "    svc = LinearSVC(penalty='l1', dual=False, C=best_C, random_state = 42)\n",
    "    svc.fit(x_train, y_train)\n",
    "    \n",
    "    list1 = []\n",
    "     # accuracy\n",
    "    train_accuracy = svc.score(x_train, y_train)\n",
    "    test_accuracy = svc.score(x_test, y_test)\n",
    "    list1.append(train_accuracy)\n",
    "    list1.append(test_accuracy)\n",
    "    print('train_acc is ', train_accuracy)\n",
    "    print('test_acc is ', test_accuracy)\n",
    "    \n",
    "    # confusion matrix\n",
    "    y_train_predict = svc.predict(x_train)\n",
    "    y_test_predict = svc.predict(x_test)\n",
    "    train_confusion_matrix = confusion_matrix(y_train, y_train_predict)\n",
    "    test_confusion_matrix = confusion_matrix(y_test, y_test_predict)\n",
    "    \n",
    "    # get required values from confusion matrix using ravel\n",
    "    # source: https://stackoverflow.com/questions/46229965/how-to-make-sklearn-metrics-confusion\n",
    "    # -matrix-to-always-return-tp-tn-fp-fn\n",
    "    train_tn, train_fp, train_fn, train_tp = train_confusion_matrix.ravel()\n",
    "    test_tn, test_fp, test_fn, test_tp = test_confusion_matrix.ravel()\n",
    "    # precision: p = tp/(tp+fp)\n",
    "    train_precision = train_tp/(train_tp + train_fp)    \n",
    "    test_precision = test_tp/(test_tp + test_fp)\n",
    "    list1.append(train_precision)\n",
    "    list1.append(test_precision)\n",
    "\n",
    "    # recall: tp/(tp+fn)\n",
    "    train_recall = train_tp/(train_tp + train_fn)\n",
    "    test_recall = test_tp/(test_tp + test_fn)\n",
    "    list1.append(train_recall)\n",
    "    list1.append(test_recall)\n",
    "    \n",
    "    # f1 = 2 * (P*R)/(P+R)\n",
    "    train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall)\n",
    "    test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "    list1.append(train_f1)\n",
    "    list1.append(test_f1)\n",
    "    \n",
    "    # AUC\n",
    "    train_predict_prob = svc.decision_function(x_train)\n",
    "    test_predict_prob = svc.decision_function(x_test)\n",
    "    train_auc = roc_auc_score(y_train, train_predict_prob)\n",
    "    test_auc = roc_auc_score(y_test, test_predict_prob)\n",
    "    list1.append(train_auc)\n",
    "    list1.append(test_auc)\n",
    "    print('\\n')\n",
    "    return list1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6c27428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  1\n",
      "best c is:  1.0\n",
      "train_acc is  0.989010989010989\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  2\n",
      "best c is:  1.0\n",
      "train_acc is  0.9912087912087912\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  3\n",
      "best c is:  0.1\n",
      "train_acc is  0.989010989010989\n",
      "test_acc is  0.9912280701754386\n",
      "\n",
      "\n",
      "M =  4\n",
      "best c is:  0.1\n",
      "train_acc is  0.978021978021978\n",
      "test_acc is  0.9912280701754386\n",
      "\n",
      "\n",
      "M =  5\n",
      "best c is:  0.1\n",
      "train_acc is  0.9846153846153847\n",
      "test_acc is  0.9736842105263158\n",
      "\n",
      "\n",
      "M =  6\n",
      "best c is:  0.1\n",
      "train_acc is  0.9868131868131869\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  7\n",
      "best c is:  1.0\n",
      "train_acc is  0.9956043956043956\n",
      "test_acc is  0.9385964912280702\n",
      "\n",
      "\n",
      "M =  8\n",
      "best c is:  0.1\n",
      "train_acc is  0.9846153846153847\n",
      "test_acc is  0.956140350877193\n",
      "\n",
      "\n",
      "M =  9\n",
      "best c is:  0.1\n",
      "train_acc is  0.989010989010989\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  10\n",
      "best c is:  1.0\n",
      "train_acc is  0.989010989010989\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  11\n",
      "best c is:  0.1\n",
      "train_acc is  0.9824175824175824\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  12\n",
      "best c is:  100.0\n",
      "train_acc is  1.0\n",
      "test_acc is  0.9298245614035088\n",
      "\n",
      "\n",
      "M =  13\n",
      "best c is:  1.0\n",
      "train_acc is  0.9846153846153847\n",
      "test_acc is  0.9736842105263158\n",
      "\n",
      "\n",
      "M =  14\n",
      "best c is:  0.1\n",
      "train_acc is  0.9912087912087912\n",
      "test_acc is  0.956140350877193\n",
      "\n",
      "\n",
      "M =  15\n",
      "best c is:  0.1\n",
      "train_acc is  0.989010989010989\n",
      "test_acc is  0.9473684210526315\n",
      "\n",
      "\n",
      "M =  16\n",
      "best c is:  100.0\n",
      "train_acc is  1.0\n",
      "test_acc is  0.9736842105263158\n",
      "\n",
      "\n",
      "M =  17\n",
      "best c is:  0.1\n",
      "train_acc is  0.9846153846153847\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  18\n",
      "best c is:  1.0\n",
      "train_acc is  0.9912087912087912\n",
      "test_acc is  0.9736842105263158\n",
      "\n",
      "\n",
      "M =  19\n",
      "best c is:  0.1\n",
      "train_acc is  0.9846153846153847\n",
      "test_acc is  0.956140350877193\n",
      "\n",
      "\n",
      "M =  20\n",
      "best c is:  0.1\n",
      "train_acc is  0.9846153846153847\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  21\n",
      "best c is:  1.0\n",
      "train_acc is  0.9912087912087912\n",
      "test_acc is  0.9473684210526315\n",
      "\n",
      "\n",
      "M =  22\n",
      "best c is:  0.1\n",
      "train_acc is  0.9868131868131869\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  23\n",
      "best c is:  0.1\n",
      "train_acc is  0.9868131868131869\n",
      "test_acc is  0.9912280701754386\n",
      "\n",
      "\n",
      "M =  24\n",
      "best c is:  0.1\n",
      "train_acc is  0.9846153846153847\n",
      "test_acc is  0.956140350877193\n",
      "\n",
      "\n",
      "M =  25\n",
      "best c is:  0.1\n",
      "train_acc is  0.9824175824175824\n",
      "test_acc is  0.9736842105263158\n",
      "\n",
      "\n",
      "M =  26\n",
      "best c is:  0.1\n",
      "train_acc is  0.9824175824175824\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  27\n",
      "best c is:  0.1\n",
      "train_acc is  0.978021978021978\n",
      "test_acc is  0.9912280701754386\n",
      "\n",
      "\n",
      "M =  28\n",
      "best c is:  0.1\n",
      "train_acc is  0.9824175824175824\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  29\n",
      "best c is:  0.1\n",
      "train_acc is  0.989010989010989\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  30\n",
      "best c is:  0.1\n",
      "train_acc is  0.978021978021978\n",
      "test_acc is  0.9736842105263158\n",
      "\n",
      "\n",
      "summary of the performance:\n",
      " train_accuracy     0.987033\n",
      "test_accuracy      0.969883\n",
      "train_precision    0.992006\n",
      "test_precision     0.973170\n",
      "train_recall       0.973137\n",
      "test_recall        0.945238\n",
      "train_f1           0.982453\n",
      "test_f1            0.958587\n",
      "train_auc          0.997535\n",
      "test_auc           0.992119\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols = ['train_accuracy', 'test_accuracy', 'train_precision', 'test_precision', 'train_recall','test_recall', \\\n",
    "       'train_f1', 'test_f1', 'train_auc', 'test_auc']\n",
    "table_i = pd.DataFrame(columns=cols, index=range(M))\n",
    "for i in range(M):\n",
    "    print('M = ', i+1)\n",
    "    table_i.loc[i] = Supervised_learning(std_X, y)\n",
    "print('summary of the performance:\\n', table_i.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "63202c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['supervised_learning'] = table_i.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3986de7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supervised_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.987033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.969883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.992006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.973170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.973137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.945238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.982453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.958587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc</th>\n",
       "      <td>0.997535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc</th>\n",
       "      <td>0.992119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 supervised_learning\n",
       "train_accuracy              0.987033\n",
       "test_accuracy               0.969883\n",
       "train_precision             0.992006\n",
       "test_precision              0.973170\n",
       "train_recall                0.973137\n",
       "test_recall                 0.945238\n",
       "train_f1                    0.982453\n",
       "test_f1                     0.958587\n",
       "train_auc                   0.997535\n",
       "test_auc                    0.992119"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b431cddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_confusion_matrix \n",
      " [[282   3]\n",
      " [  6 164]]\n",
      "test_confusion_matrix \n",
      " [[72  0]\n",
      " [ 3 39]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick one run\n",
    "from sklearn import metrics\n",
    "c_range= [10**c for c in np.arange(-3,7, dtype=float)]\n",
    "params = {'C':c_range}\n",
    "Linear_SVC = LinearSVC(penalty = 'l1', dual=False, random_state = 42)\n",
    "clf = GridSearchCV(Linear_SVC, params, cv=5)\n",
    "clf.fit(std_X_train, y_train)\n",
    "best_C = clf.best_params_['C']\n",
    "\n",
    "#build l1svm with best c\n",
    "svc = LinearSVC(penalty='l1', dual=False, C=best_C, random_state = 42)\n",
    "svc.fit(std_X_train, y_train)\n",
    "y_train_predict = svc.predict(std_X_train)\n",
    "y_test_predict = svc.predict(std_X_test)\n",
    "train_confusion_matrix = confusion_matrix(y_train, y_train_predict)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_predict)\n",
    "print('train_confusion_matrix \\n', train_confusion_matrix)\n",
    "print('test_confusion_matrix \\n', test_confusion_matrix)\n",
    "\n",
    "train_predict_prob = svc.decision_function(std_X_train)\n",
    "test_predict_prob = svc.decision_function(std_X_test)\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, train_predict_prob)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, test_predict_prob)\n",
    "fig, axes = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# axes.plot(train_fpr, train_tpr, label='train ROC curve')\n",
    "auc1 = round(metrics.auc(train_fpr, train_tpr), 4)\n",
    "auc2 = round(metrics.auc(test_fpr, test_tpr), 4)\n",
    "axes.plot(train_fpr, train_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('training', auc1))\n",
    "axes.plot(test_fpr, test_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('testing', auc2))\n",
    "axes.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89655b25",
   "metadata": {},
   "source": [
    "#### ii.Semi-Supervised Learning/ Self-training: select 50% of the positive class along with 50% of the negative class in the training set as labeled data and the rest as unlabelled data. You can select them randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f22ff1",
   "metadata": {},
   "source": [
    "#### A.Train an L1-penalized SVM to classify the labeled data Use normalized data. Choose the penalty parameter using 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d7d63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_X_train2, std_X_test2, y_train2, y_test2 = train_test_split(std_X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1558d588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(dual=False, penalty=&#x27;l1&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(dual=False, penalty=&#x27;l1&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(dual=False, penalty='l1', random_state=42)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_range= [10**c for c in np.arange(-3,7, dtype=float)]\n",
    "params = {'C':c_range}\n",
    "Linear_SVC = LinearSVC(penalty = 'l1', dual=False, random_state = 42)\n",
    "clf = GridSearchCV(Linear_SVC, params, cv=5)\n",
    "clf.fit(std_X_train2, y_train2)\n",
    "best_C = clf.best_params_['C']\n",
    "\n",
    "#build l1svm with best c\n",
    "svc = LinearSVC(penalty='l1', dual=False, C=best_C, random_state = 42)\n",
    "svc.fit(std_X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f42f8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semiSupervised_learning(x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.5, random_state = None)\n",
    "    \n",
    "    \n",
    "    c_range= [10**c for c in np.arange(-3,7, dtype=float)]\n",
    "    params = {'C':c_range}\n",
    "    Linear_SVC = LinearSVC(penalty = 'l1', dual=False, random_state = 42)\n",
    "    clf = GridSearchCV(Linear_SVC, params, cv=5)\n",
    "    clf.fit(x_train, y_train)\n",
    "    best_C = clf.best_params_['C']\n",
    "    \n",
    "    print('best c is:' ,best_C)\n",
    "    \n",
    "    #build l1svm with best c\n",
    "    svc = LinearSVC(penalty='l1', dual=False, C=best_C, random_state = 42)\n",
    "    svc.fit(x_train, y_train)\n",
    "    \n",
    "                                                                            \n",
    "    unlabel_x = x_test                                                                            \n",
    "    while len(unlabel_x) > 0:\n",
    "        #Find the unlabeled data point that is the farthest from the SVM decision boundary. \n",
    "        distance_from_bound = svc.decision_function(unlabel_x)\n",
    "        abs_distance = np.abs(distance_from_bound)\n",
    "        ## get index of max distance point\n",
    "        index = abs_distance.argmax()\n",
    "#         print(len(unlabel_x))\n",
    "\n",
    "        #find label of this point\n",
    "        label = 0 if distance_from_bound[index] < 0 else 1\n",
    "\n",
    "        #Add this point back into the training and testing\n",
    "        label_x = pd.DataFrame(data = x_train)\n",
    "        unlabel_x = pd.DataFrame(data = unlabel_x)                                                                  \n",
    "        new_x_train = np.append(label_x, [unlabel_x.iloc[index]], axis = 0)                                                                  \n",
    "        new_y_train = y_train.append(pd.Series(label))\n",
    "\n",
    "        #Remove this point from the unlabeled dataframe\n",
    "        unlabel_x = unlabel_x.drop(unlabel_x.index[index])\n",
    "#         print(unlabel_x)\n",
    "\n",
    "        #Retrain the SVM with the updated dataset\n",
    "        svc.fit(new_x_train, new_y_train)\n",
    "    \n",
    "    list1 = []\n",
    "     # accuracy\n",
    "    train_accuracy = svc.score(x_train, y_train)\n",
    "    test_accuracy = svc.score(x_test, y_test)\n",
    "    list1.append(train_accuracy)\n",
    "    list1.append(test_accuracy)\n",
    "    print('train_acc is ', train_accuracy)\n",
    "    print('test_acc is ', test_accuracy)\n",
    "    \n",
    "    # confusion matrix\n",
    "    y_train_predict = svc.predict(x_train)\n",
    "    y_test_predict = svc.predict(x_test)\n",
    "    train_confusion_matrix = confusion_matrix(y_train, y_train_predict)\n",
    "    test_confusion_matrix = confusion_matrix(y_test, y_test_predict)\n",
    "    \n",
    "    # get required values from confusion matrix using ravel\n",
    "    # source: https://stackoverflow.com/questions/46229965/how-to-make-sklearn-metrics-confusion\n",
    "    # -matrix-to-always-return-tp-tn-fp-fn\n",
    "    train_tn, train_fp, train_fn, train_tp = train_confusion_matrix.ravel()\n",
    "    test_tn, test_fp, test_fn, test_tp = test_confusion_matrix.ravel()\n",
    "    # precision: p = tp/(tp+fp)\n",
    "    train_precision = train_tp/(train_tp + train_fp)    \n",
    "    test_precision = test_tp/(test_tp + test_fp)\n",
    "    list1.append(train_precision)\n",
    "    list1.append(test_precision)\n",
    "\n",
    "    # recall: tp/(tp+fn)\n",
    "    train_recall = train_tp/(train_tp + train_fn)\n",
    "    test_recall = test_tp/(test_tp + test_fn)\n",
    "    list1.append(train_recall)\n",
    "    list1.append(test_recall)\n",
    "    \n",
    "    # f1 = 2 * (P*R)/(P+R)\n",
    "    train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall)\n",
    "    test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "    list1.append(train_f1)\n",
    "    list1.append(test_f1)\n",
    "    \n",
    "    # AUC\n",
    "    train_predict_prob = svc.decision_function(x_train)\n",
    "    test_predict_prob = svc.decision_function(x_test)\n",
    "    train_auc = roc_auc_score(y_train, train_predict_prob)\n",
    "    test_auc = roc_auc_score(y_test, test_predict_prob)\n",
    "    list1.append(train_auc)\n",
    "    list1.append(test_auc)\n",
    "    print('\\n')\n",
    "    return [list1, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "12d8617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  1\n",
      "best c is: 0.1\n",
      "train_acc is  0.9823943661971831\n",
      "test_acc is  0.9578947368421052\n",
      "\n",
      "\n",
      "M =  2\n",
      "best c is: 0.1\n",
      "train_acc is  0.9894366197183099\n",
      "test_acc is  0.9754385964912281\n",
      "\n",
      "\n",
      "M =  3\n",
      "best c is: 0.1\n",
      "train_acc is  0.9788732394366197\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  4\n",
      "best c is: 0.1\n",
      "train_acc is  0.9859154929577465\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  5\n",
      "best c is: 1.0\n",
      "train_acc is  0.9859154929577465\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  6\n",
      "best c is: 0.1\n",
      "train_acc is  0.9894366197183099\n",
      "test_acc is  0.9754385964912281\n",
      "\n",
      "\n",
      "M =  7\n",
      "best c is: 0.1\n",
      "train_acc is  0.9859154929577465\n",
      "test_acc is  0.9754385964912281\n",
      "\n",
      "\n",
      "M =  8\n",
      "best c is: 1.0\n",
      "train_acc is  0.9929577464788732\n",
      "test_acc is  0.9508771929824561\n",
      "\n",
      "\n",
      "M =  9\n",
      "best c is: 0.1\n",
      "train_acc is  0.9823943661971831\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  10\n",
      "best c is: 1.0\n",
      "train_acc is  0.9929577464788732\n",
      "test_acc is  0.9719298245614035\n",
      "\n",
      "\n",
      "M =  11\n",
      "best c is: 1000.0\n",
      "train_acc is  1.0\n",
      "test_acc is  0.9614035087719298\n",
      "\n",
      "\n",
      "M =  12\n",
      "best c is: 0.1\n",
      "train_acc is  0.9753521126760564\n",
      "test_acc is  0.9859649122807017\n",
      "\n",
      "\n",
      "M =  13\n",
      "best c is: 1.0\n",
      "train_acc is  0.9859154929577465\n",
      "test_acc is  0.9543859649122807\n",
      "\n",
      "\n",
      "M =  14\n",
      "best c is: 1.0\n",
      "train_acc is  0.9894366197183099\n",
      "test_acc is  0.9578947368421052\n",
      "\n",
      "\n",
      "M =  15\n",
      "best c is: 1.0\n",
      "train_acc is  0.9859154929577465\n",
      "test_acc is  0.9614035087719298\n",
      "\n",
      "\n",
      "M =  16\n",
      "best c is: 0.1\n",
      "train_acc is  0.9823943661971831\n",
      "test_acc is  0.9719298245614035\n",
      "\n",
      "\n",
      "M =  17\n",
      "best c is: 0.1\n",
      "train_acc is  0.9859154929577465\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  18\n",
      "best c is: 0.1\n",
      "train_acc is  0.9788732394366197\n",
      "test_acc is  0.9789473684210527\n",
      "\n",
      "\n",
      "M =  19\n",
      "best c is: 1.0\n",
      "train_acc is  0.9894366197183099\n",
      "test_acc is  0.9543859649122807\n",
      "\n",
      "\n",
      "M =  20\n",
      "best c is: 0.1\n",
      "train_acc is  0.9823943661971831\n",
      "test_acc is  0.9754385964912281\n",
      "\n",
      "\n",
      "M =  21\n",
      "best c is: 10.0\n",
      "train_acc is  1.0\n",
      "test_acc is  0.968421052631579\n",
      "\n",
      "\n",
      "M =  22\n",
      "best c is: 1.0\n",
      "train_acc is  0.9929577464788732\n",
      "test_acc is  0.9543859649122807\n",
      "\n",
      "\n",
      "M =  23\n",
      "best c is: 10.0\n",
      "train_acc is  1.0\n",
      "test_acc is  0.9578947368421052\n",
      "\n",
      "\n",
      "M =  24\n",
      "best c is: 1.0\n",
      "train_acc is  0.9929577464788732\n",
      "test_acc is  0.9578947368421052\n",
      "\n",
      "\n",
      "M =  25\n",
      "best c is: 0.1\n",
      "train_acc is  0.9683098591549296\n",
      "test_acc is  0.9789473684210527\n",
      "\n",
      "\n",
      "M =  26\n",
      "best c is: 0.1\n",
      "train_acc is  0.9929577464788732\n",
      "test_acc is  0.9649122807017544\n",
      "\n",
      "\n",
      "M =  27\n",
      "best c is: 0.1\n",
      "train_acc is  0.9788732394366197\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "M =  28\n",
      "best c is: 100.0\n",
      "train_acc is  1.0\n",
      "test_acc is  0.9543859649122807\n",
      "\n",
      "\n",
      "M =  29\n",
      "best c is: 0.1\n",
      "train_acc is  0.9788732394366197\n",
      "test_acc is  0.9614035087719298\n",
      "\n",
      "\n",
      "M =  30\n",
      "best c is: 0.1\n",
      "train_acc is  0.9788732394366197\n",
      "test_acc is  0.9824561403508771\n",
      "\n",
      "\n",
      "summary of the performance:\n",
      " train_accuracy     0.986854\n",
      "test_accuracy      0.967135\n",
      "train_precision    0.994241\n",
      "test_precision     0.972059\n",
      "train_recall       0.970440\n",
      "test_recall        0.939308\n",
      "train_f1           0.982110\n",
      "test_f1            0.954985\n",
      "train_auc          0.997952\n",
      "test_auc           0.991718\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols = ['train_accuracy', 'test_accuracy', 'train_precision', 'test_precision', 'train_recall','test_recall', \\\n",
    "       'train_f1', 'test_f1', 'train_auc', 'test_auc']\n",
    "table_ii = pd.DataFrame(columns=cols, index=range(M))\n",
    "for i in range(M):\n",
    "    print('M = ', i+1)\n",
    "    a = semiSupervised_learning(std_X, y)\n",
    "    table_ii.loc[i] = a[0]\n",
    "print('summary of the performance:\\n', table_ii.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d46f2654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_confusion_matrix \n",
      " [[282   3]\n",
      " [  5 165]]\n",
      "test_confusion_matrix \n",
      " [[71  1]\n",
      " [ 2 40]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pick the last run\n",
    "svc = a[1]\n",
    "y_train_predict = svc.predict(std_X_train)\n",
    "y_test_predict = svc.predict(std_X_test)\n",
    "train_confusion_matrix = confusion_matrix(y_train, y_train_predict)\n",
    "test_confusion_matrix = confusion_matrix(y_test, y_test_predict)\n",
    "print('train_confusion_matrix \\n', train_confusion_matrix)\n",
    "print('test_confusion_matrix \\n', test_confusion_matrix)\n",
    "\n",
    "train_predict_prob = svc.decision_function(std_X_train)\n",
    "test_predict_prob = svc.decision_function(std_X_test)\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, train_predict_prob)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, test_predict_prob)\n",
    "fig, axes = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# axes.plot(train_fpr, train_tpr, label='train ROC curve')\n",
    "auc1 = round(metrics.auc(train_fpr, train_tpr), 4)\n",
    "auc2 = round(metrics.auc(test_fpr, test_tpr), 4)\n",
    "axes.plot(train_fpr, train_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('training', auc1))\n",
    "axes.plot(test_fpr, test_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('testing', auc2))\n",
    "axes.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.title('ROC curve of semi_supervised learning')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "715965a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['semi-supervised_learning'] = table_ii.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "24467bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supervised_learning</th>\n",
       "      <th>semi-supervised_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.987033</td>\n",
       "      <td>0.986854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.969883</td>\n",
       "      <td>0.967135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.992006</td>\n",
       "      <td>0.994241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.972059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.973137</td>\n",
       "      <td>0.970440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.939308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.982110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.958587</td>\n",
       "      <td>0.954985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc</th>\n",
       "      <td>0.997535</td>\n",
       "      <td>0.997952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc</th>\n",
       "      <td>0.992119</td>\n",
       "      <td>0.991718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 supervised_learning  semi-supervised_learning\n",
       "train_accuracy              0.987033                  0.986854\n",
       "test_accuracy               0.969883                  0.967135\n",
       "train_precision             0.992006                  0.994241\n",
       "test_precision              0.973170                  0.972059\n",
       "train_recall                0.973137                  0.970440\n",
       "test_recall                 0.945238                  0.939308\n",
       "train_f1                    0.982453                  0.982110\n",
       "test_f1                     0.958587                  0.954985\n",
       "train_auc                   0.997535                  0.997952\n",
       "test_auc                    0.992119                  0.991718"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396a3d6",
   "metadata": {},
   "source": [
    "#### iii.Unsupervised Learning:Run k-means algorithm on the whole training set. Ignore the labels of the data, and assume k= 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1d882",
   "metadata": {},
   "source": [
    "#### A.Run the k-means algorithm multiple times. Make sure that you initialize the algoritm randomly. How do you make sure that the algorithm was not trapped in a local minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "801760c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(std_X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.5, random_state = 42)\n",
    "kmeans = KMeans(n_clusters=2, n_init = 65, random_state = 42).fit(x_train)\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b4ac2",
   "metadata": {},
   "source": [
    "Ans: K-Means should be re-run a few times with different parameters so that the algorithm was not trapped in a local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0fe2a",
   "metadata": {},
   "source": [
    "#### B. Compute the centers of the two clusters and find the closest 30 data points to each center. Read the true labels of those 30 data points and take a majority poll within them. The majority poll becomes the label predicted by k-means for the members of each cluster. Then compare the labels provided by k-means with the true labels of the training data and report the average accuracy, precision, recall,F1-score, and AUC over M runs, and ROC and the confusion matrix for one of the runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15752740",
   "metadata": {},
   "source": [
    "#### C.Classify test data based on their proximity to the centers of the clusters. Report the average accuracy, precision, recall,F1-score, and AUC over Mruns, and ROC and the confusion matrix for one of the runs for the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f85c3",
   "metadata": {},
   "source": [
    "Note: I performed training data and testing data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6ede4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(std_X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "283c63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(x_train, x_test, y_train, y_test):\n",
    "    kmeans = KMeans(n_clusters=2, n_init = 65, random_state = 42).fit(x_train)\n",
    "    klabels = kmeans.labels_\n",
    "    centers = kmeans.cluster_centers_\n",
    "    index_cluster_0 = np.where(klabels==0)\n",
    "    index_cluster_1 = np.where(klabels==1)\n",
    "    indexes = [index_cluster_0, index_cluster_1]\n",
    "    \n",
    "    list2 = []\n",
    "    for i in range(2):\n",
    "        cluster = np.array(x_train)[indexes[i]]\n",
    "        labels = np.array(y_train)[indexes[i]]\n",
    "        distances = np.empty(0)\n",
    "        for x in cluster:\n",
    "            d = np.linalg.norm(x - centers[i])\n",
    "            distances = np.append(distances, d)\n",
    "        orders = distances.argsort()\n",
    "        labels = labels[orders[:30]]\n",
    "        num = np.bincount(labels)\n",
    "        maj = np.argmax(num)\n",
    "        list2.append(maj)\n",
    "\n",
    "    ## training set\n",
    "    train_pred = klabels\n",
    "    cluster_0 = list2[0]\n",
    "    cluster_1 = list2[1]\n",
    "    train_pred[cluster_0] = cluster_0\n",
    "    \n",
    "    train_pred[cluster_1] = cluster_1\n",
    "    \n",
    "    ## testing set\n",
    "    test_labels = kmeans.predict(x_test)\n",
    "    index_cluster_0_test = np.where(test_labels==0)\n",
    "    index_cluster_1_test = np.where(test_labels==1)\n",
    "    \n",
    "    test_pred = test_labels\n",
    "    test_pred[index_cluster_0_test] = cluster_0\n",
    "    test_pred[index_cluster_1_test] = cluster_1\n",
    "    \n",
    "    list1 = []\n",
    "    # accuracy\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    list1.append(train_accuracy)\n",
    "    list1.append(test_accuracy)\n",
    "#     print('train_acc is ', train_accuracy)\n",
    "#     print('test_acc is ', test_accuracy)\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_confusion_matrix = confusion_matrix(y_train, train_pred)\n",
    "    test_confusion_matrix = confusion_matrix(y_test, test_pred)\n",
    "#     list1.append(train_confusion_matrix)\n",
    "#     list1.append(test_confusion_matrix)\n",
    "    \n",
    "    # get required values from confusion matrix using ravel\n",
    "    # source: https://stackoverflow.com/questions/46229965/how-to-make-sklearn-metrics-confusion\n",
    "    # -matrix-to-always-return-tp-tn-fp-fn\n",
    "    train_tn, train_fp, train_fn, train_tp = train_confusion_matrix.ravel()\n",
    "    test_tn, test_fp, test_fn, test_tp = test_confusion_matrix.ravel()\n",
    "    # precision: p = tp/(tp+fp)\n",
    "    train_precision = train_tp/(train_tp + train_fp)    \n",
    "    test_precision = test_tp/(test_tp + test_fp)\n",
    "    list1.append(train_precision)\n",
    "    list1.append(test_precision)\n",
    "\n",
    "    # recall: tp/(tp+fn)\n",
    "    train_recall = train_tp/(train_tp + train_fn)\n",
    "    test_recall = test_tp/(test_tp + test_fn)\n",
    "    list1.append(train_recall)\n",
    "    list1.append(test_recall)\n",
    "    \n",
    "    # f1 = 2 * (P*R)/(P+R)\n",
    "    train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall)\n",
    "    test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "    list1.append(train_f1)\n",
    "    list1.append(test_f1)\n",
    "    \n",
    "    # AUC\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc = roc_auc_score(y_test, test_pred)\n",
    "    list1.append(train_auc)\n",
    "    list1.append(test_auc)\n",
    "#     print('\\n')\n",
    "    return list1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3b22bee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of the performance:\n",
      " train_accuracy     0.909890\n",
      "test_accuracy      0.903509\n",
      "train_precision    0.916129\n",
      "test_precision     0.942857\n",
      "train_recall       0.835294\n",
      "test_recall        0.785714\n",
      "train_f1           0.873846\n",
      "test_f1            0.857143\n",
      "train_auc          0.894840\n",
      "test_auc           0.878968\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols = ['train_accuracy', 'test_accuracy', 'train_precision', 'test_precision', 'train_recall','test_recall', \\\n",
    "       'train_f1', 'test_f1', 'train_auc', 'test_auc']\n",
    "table_iii = pd.DataFrame(columns=cols, index=range(M))\n",
    "for i in range(M):\n",
    "#     print('M = ', i+1)\n",
    "    table_iii.loc[i] = k_means(x_train, x_test, y_train, y_test)\n",
    "print('summary of the performance:\\n', table_iii.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800081e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d4218aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_confusion_matrix \n",
      " [[272  13]\n",
      " [ 28 142]]\n",
      "test_confusion_matrix \n",
      " [[70  2]\n",
      " [ 9 33]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick one run\n",
    "kmeans = KMeans(n_clusters=2, n_init = 65, random_state = 42).fit(x_train)\n",
    "klabels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "index_cluster_0 = np.where(klabels==0)\n",
    "index_cluster_1 = np.where(klabels==1)\n",
    "indexes = [index_cluster_0, index_cluster_1]\n",
    "    \n",
    "list2 = []\n",
    "for i in range(2):\n",
    "    cluster = np.array(x_train)[indexes[i]]\n",
    "    labels = np.array(y_train)[indexes[i]]\n",
    "    distances = np.empty(0)\n",
    "    for x in cluster:\n",
    "        d = np.linalg.norm(x - centers[i])\n",
    "        distances = np.append(distances, d)\n",
    "    orders = distances.argsort()\n",
    "    labels = labels[orders[:30]]\n",
    "    num = np.bincount(labels)\n",
    "    maj = np.argmax(num)\n",
    "    list2.append(maj)\n",
    "\n",
    "## training set\n",
    "train_pred = klabels\n",
    "cluster_0 = list2[0]\n",
    "cluster_1 = list2[1]\n",
    "train_pred[cluster_0] = cluster_0    \n",
    "train_pred[cluster_1] = cluster_1\n",
    "    \n",
    "## testing set\n",
    "test_labels = kmeans.predict(x_test)\n",
    "index_cluster_0_test = np.where(test_labels==0)\n",
    "index_cluster_1_test = np.where(test_labels==1)\n",
    "    \n",
    "test_pred = test_labels\n",
    "test_pred[index_cluster_0_test] = cluster_0\n",
    "test_pred[index_cluster_1_test] = cluster_1\n",
    "\n",
    "train_confusion_matrix = confusion_matrix(y_train, train_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, test_pred)\n",
    "print('train_confusion_matrix \\n', train_confusion_matrix)\n",
    "print('test_confusion_matrix \\n', test_confusion_matrix)\n",
    "\n",
    "y_pred_train = pd.DataFrame(kmeans.transform(x_train)).iloc[:,0]\n",
    "y_pred_test = pd.DataFrame(kmeans.transform(x_test)).iloc[:,0]\n",
    "                            \n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_pred_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_pred_test)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# axes.plot(train_fpr, train_tpr, label='train ROC curve')\n",
    "auc1 = round(metrics.auc(train_fpr, train_tpr), 4)\n",
    "auc2 = round(metrics.auc(test_fpr, test_tpr), 4)\n",
    "axes.plot(train_fpr, train_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('training', auc1))\n",
    "axes.plot(test_fpr, test_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('testing', auc2))\n",
    "axes.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.title('ROC curve of semi_supervised learning')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "5a0b6b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supervised_learning</th>\n",
       "      <th>semi-supervised_learning</th>\n",
       "      <th>unsupervised_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.987033</td>\n",
       "      <td>0.986854</td>\n",
       "      <td>0.909890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.969883</td>\n",
       "      <td>0.967135</td>\n",
       "      <td>0.903509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.992006</td>\n",
       "      <td>0.994241</td>\n",
       "      <td>0.916129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.972059</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.973137</td>\n",
       "      <td>0.970440</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.939308</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.982110</td>\n",
       "      <td>0.873846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.958587</td>\n",
       "      <td>0.954985</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc</th>\n",
       "      <td>0.997535</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.894840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc</th>\n",
       "      <td>0.992119</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.878968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 supervised_learning  semi-supervised_learning  \\\n",
       "train_accuracy              0.987033                  0.986854   \n",
       "test_accuracy               0.969883                  0.967135   \n",
       "train_precision             0.992006                  0.994241   \n",
       "test_precision              0.973170                  0.972059   \n",
       "train_recall                0.973137                  0.970440   \n",
       "test_recall                 0.945238                  0.939308   \n",
       "train_f1                    0.982453                  0.982110   \n",
       "test_f1                     0.958587                  0.954985   \n",
       "train_auc                   0.997535                  0.997952   \n",
       "test_auc                    0.992119                  0.991718   \n",
       "\n",
       "                 unsupervised_learning  \n",
       "train_accuracy                0.909890  \n",
       "test_accuracy                 0.903509  \n",
       "train_precision               0.916129  \n",
       "test_precision                0.942857  \n",
       "train_recall                  0.835294  \n",
       "test_recall                   0.785714  \n",
       "train_f1                      0.873846  \n",
       "test_f1                       0.857143  \n",
       "train_auc                     0.894840  \n",
       "test_auc                      0.878968  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries['unsupervised_learning'] = table_iii.mean()\n",
    "pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e660f96",
   "metadata": {},
   "source": [
    "#### iv.Spectral Clustering: Repeat 1(b)iii using spectral clustering, which is clustering based on kernels.Research what spectral clustering is. Use RBF kernel with gamma=1 or find a gamma for which the two clutsres have the same balance as the one in original data set (if the positive class has p and the negative class has n samples, the two clusters must have p and n members). Do not label data based on their proximity to cluster center, because spectral clustering may give you non-convex clusters . Instead, use fit−predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e530a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spectral(x_train, x_test, y_train, y_test):\n",
    "    spectral = SpectralClustering(n_clusters=2, gamma=1, affinity='rbf').fit(x_train)\n",
    "    labels = spectral.labels_\n",
    "    # get two clusters center\n",
    "    index_cluster_0 = np.where(labels==0)\n",
    "    index_cluster_1 = np.where(labels==1)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    cluster_0 = np.argmax(np.bincount(y_train[index_cluster_0]))\n",
    "    cluster_1 = np.argmax(np.bincount(y_train[index_cluster_1]))\n",
    "\n",
    "    # training data\n",
    "    train_pred = labels\n",
    "    train_pred[cluster_0] = cluster_0\n",
    "    train_pred[cluster_1] = cluster_1\n",
    "    \n",
    "    # testing data\n",
    "    test_labels = spectral.fit_predict(x_test)\n",
    "    test_cluster_0 = np.where(test_labels==0)\n",
    "    test_cluster_1 = np.where(test_labels==1)\n",
    "    \n",
    "    test_pred = test_labels\n",
    "    test_pred[test_cluster_0] = cluster_0\n",
    "    test_pred[test_cluster_1] = cluster_1\n",
    "    \n",
    "    list1 = []\n",
    "    # accuracy \n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    list1.append(train_accuracy)\n",
    "    list1.append(test_accuracy)\n",
    "\n",
    "    # get confusion matrix\n",
    "    train_confusion_matrix = confusion_matrix(y_train, train_pred)\n",
    "    train_confusion_matrix = confusion_matrix(y_test, test_pred)\n",
    "    \n",
    "    # get required values from confusion matrix using ravel\n",
    "    # source: https://stackoverflow.com/questions/46229965/how-to-make-sklearn-metrics-confusion\n",
    "    # -matrix-to-always-return-tp-tn-fp-fn\n",
    "    train_tn, train_fp, train_fn, train_tp = train_confusion_matrix.ravel()\n",
    "    test_tn, test_fp, test_fn, test_tp = test_confusion_matrix.ravel()\n",
    "    # precision: p = tp/(tp+fp)\n",
    "    train_precision = train_tp/(train_tp + train_fp)    \n",
    "    test_precision = test_tp/(test_tp + test_fp)\n",
    "    list1.append(train_precision)\n",
    "    list1.append(test_precision)\n",
    "\n",
    "    # recall: tp/(tp+fn)\n",
    "    train_recall = train_tp/(train_tp + train_fn)\n",
    "    test_recall = test_tp/(test_tp + test_fn)\n",
    "    list1.append(train_recall)\n",
    "    list1.append(test_recall)\n",
    "    \n",
    "    # f1 = 2 * (P*R)/(P+R)\n",
    "    train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall)\n",
    "    test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "    list1.append(train_f1)\n",
    "    list1.append(test_f1)\n",
    "    \n",
    "    # AUC\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc = roc_auc_score(y_test, test_pred)\n",
    "    list1.append(train_auc)\n",
    "    list1.append(test_auc)\n",
    "#     print('\\n')\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5eecbad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of the performance:\n",
      " train_accuracy     0.619853\n",
      "test_accuracy      0.692982\n",
      "train_precision    0.903030\n",
      "test_precision     0.942857\n",
      "train_recall       0.395238\n",
      "test_recall        0.785714\n",
      "train_f1           0.507204\n",
      "test_f1            0.857143\n",
      "train_auc          0.503696\n",
      "test_auc           0.630952\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols = ['train_accuracy', 'test_accuracy', 'train_precision', 'test_precision', 'train_recall','test_recall', \\\n",
    "       'train_f1', 'test_f1', 'train_auc', 'test_auc']\n",
    "table_iiii = pd.DataFrame(columns=cols, index=range(M))\n",
    "for i in range(M):\n",
    "#     print('M = ', i+1)\n",
    "    table_iiii.loc[i] = Spectral(x_train, x_test, y_train, y_test)\n",
    "print('summary of the performance:\\n', table_iiii.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "a3338508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_confusion_matrix \n",
      " [[284   1]\n",
      " [168   2]]\n",
      "test_confusion_matrix \n",
      " [[ 0 72]\n",
      " [15 27]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pick one run\n",
    "spectral = SpectralClustering(n_clusters=2, gamma=1, affinity='rbf').fit(x_train)\n",
    "labels = spectral.labels_\n",
    "# get two clusters center\n",
    "index_cluster_0 = np.where(labels==0)\n",
    "index_cluster_1 = np.where(labels==1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "cluster_0 = np.argmax(np.bincount(y_train[index_cluster_0]))\n",
    "cluster_1 = np.argmax(np.bincount(y_train[index_cluster_1]))\n",
    "\n",
    "# training data\n",
    "train_pred = labels\n",
    "train_pred[cluster_0] = cluster_0\n",
    "train_pred[cluster_1] = cluster_1\n",
    "    \n",
    "# testing data\n",
    "test_labels = spectral.fit_predict(x_test)\n",
    "test_cluster_0 = np.where(test_labels==0)\n",
    "test_cluster_1 = np.where(test_labels==1)\n",
    "    \n",
    "test_pred = test_labels\n",
    "test_pred[test_cluster_0] = cluster_0\n",
    "test_pred[test_cluster_1] = cluster_1\n",
    "\n",
    "\n",
    "train_confusion_matrix = confusion_matrix(y_train, train_pred)\n",
    "test_confusion_matrix = confusion_matrix(y_test, test_pred)\n",
    "print('train_confusion_matrix \\n', train_confusion_matrix)\n",
    "print('test_confusion_matrix \\n', test_confusion_matrix)\n",
    "\n",
    "y_pred_train = pd.DataFrame(kmeans.transform(x_train)).iloc[:,0]\n",
    "y_pred_test = pd.DataFrame(kmeans.transform(x_test)).iloc[:,0]\n",
    "                            \n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_pred_train)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_pred_test)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# axes.plot(train_fpr, train_tpr, label='train ROC curve')\n",
    "auc1 = round(metrics.auc(train_fpr, train_tpr), 4)\n",
    "auc2 = round(metrics.auc(test_fpr, test_tpr), 4)\n",
    "axes.plot(train_fpr, train_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('training', auc1))\n",
    "axes.plot(test_fpr, test_tpr, label=\"ROC Curve of {} : AUC area = {} \".format('testing', auc2))\n",
    "axes.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.title('ROC curve of unsupervised learning')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5ffa7",
   "metadata": {},
   "source": [
    "#### v. One can expect that supervised learning on the full data set works better than semi-supervised learning with half of the data set labeled.One can expect that unsupervised learning underperforms in such situations. Compare the results you obtained by those methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "4aa74a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supervised_learning</th>\n",
       "      <th>semi-supervised_learning</th>\n",
       "      <th>unsupervised_learning</th>\n",
       "      <th>unsupervised-Spectral_Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.987033</td>\n",
       "      <td>0.986854</td>\n",
       "      <td>0.909890</td>\n",
       "      <td>0.619853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.969883</td>\n",
       "      <td>0.967135</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>0.692982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.992006</td>\n",
       "      <td>0.994241</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.903030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.972059</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.973137</td>\n",
       "      <td>0.970440</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.395238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.939308</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.982453</td>\n",
       "      <td>0.982110</td>\n",
       "      <td>0.873846</td>\n",
       "      <td>0.507204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.958587</td>\n",
       "      <td>0.954985</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auc</th>\n",
       "      <td>0.997535</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.894840</td>\n",
       "      <td>0.503696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auc</th>\n",
       "      <td>0.992119</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.878968</td>\n",
       "      <td>0.630952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 supervised_learning  semi-supervised_learning  \\\n",
       "train_accuracy              0.987033                  0.986854   \n",
       "test_accuracy               0.969883                  0.967135   \n",
       "train_precision             0.992006                  0.994241   \n",
       "test_precision              0.973170                  0.972059   \n",
       "train_recall                0.973137                  0.970440   \n",
       "test_recall                 0.945238                  0.939308   \n",
       "train_f1                    0.982453                  0.982110   \n",
       "test_f1                     0.958587                  0.954985   \n",
       "train_auc                   0.997535                  0.997952   \n",
       "test_auc                    0.992119                  0.991718   \n",
       "\n",
       "                 unsupervised_learning  unsupervised-Spectral_Cluster  \n",
       "train_accuracy                0.909890                       0.619853  \n",
       "test_accuracy                 0.903509                       0.692982  \n",
       "train_precision               0.916129                       0.903030  \n",
       "test_precision                0.942857                       0.942857  \n",
       "train_recall                  0.835294                       0.395238  \n",
       "test_recall                   0.785714                       0.785714  \n",
       "train_f1                      0.873846                       0.507204  \n",
       "test_f1                       0.857143                       0.857143  \n",
       "train_auc                     0.894840                       0.503696  \n",
       "test_auc                      0.878968                       0.630952  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries['unsupervised-Spectral_Cluster'] = table_iiii.mean()\n",
    "pd.DataFrame(summaries).drop(['Spectral_Cluster'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97802407",
   "metadata": {},
   "source": [
    "Conclusion: From the table we can see that supercised_learning > semi-supercised_learning > unsupervised learning. The performance of supervised_learning and semi-superivsed learning is pretty similiar. The unsupervised learning of spectral cluster perform the worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de3886",
   "metadata": {},
   "source": [
    "## 2.Active Learning Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7d3c1",
   "metadata": {},
   "source": [
    "#### (a)Download the banknote authentication Data Set. Choose 472 data points randomly as the test set, and the remaining 900 points as the training set. This is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "78846aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1        2        3  4\n",
       "0     3.62160   8.66610  -2.8073 -0.44699  0\n",
       "1     4.54590   8.16740  -2.4586 -1.46210  0\n",
       "2     3.86600  -2.63830   1.9242  0.10645  0\n",
       "3     3.45660   9.52280  -4.0112 -3.59440  0\n",
       "4     0.32924  -4.45520   4.5718 -0.98880  0\n",
       "...       ...       ...      ...      ... ..\n",
       "1367  0.40614   1.34920  -1.4501 -0.55949  1\n",
       "1368 -1.38870  -4.87730   6.4774  0.34179  1\n",
       "1369 -3.75030 -13.45860  17.5932 -2.77710  1\n",
       "1370 -3.56370  -8.38270  12.3930 -1.28230  1\n",
       "1371 -2.54190  -0.65804   2.6842  1.19520  1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('../data/Homework_8_data/data_banknote_authentication.txt', header=None)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "976aaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data2.iloc[:,0:4]\n",
    "y = data2.iloc[:, -1:]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=472/(472+900), random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5e398",
   "metadata": {},
   "source": [
    "#### (b) Repeat each of the following two procedures 50 times. You will have 50 errors for 90 SVMs per each procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b57fd9",
   "metadata": {},
   "source": [
    "#### i. Train a SVM with a pool of 10 randomly selected data points from the training set using linear kernel and L1 penalty. Select the penalty parameter using 5-fold cross validation. Repeat this process by adding 10 other randomly selected data points to the pool, until you use all the 900 points. Do NOT replace the samples back into the training set at each step. Calculate the test error for each SVM. You will have 90 SVMs that were trained using 10, 20, 30, ... , 900 data points and their 90 test errors. You have implemented passive learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "a7cd1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## samples to select\n",
    "df_new = pd.concat([x_train,y_train])\n",
    "df_x = pd.DataFrame()\n",
    "df_y = pd.DataFrame()\n",
    "dfx_whole = x_train.copy()\n",
    "dfy_whole = y_train.copy()\n",
    "list_data_x = []\n",
    "list_data_y = []\n",
    "i = 0\n",
    "while len(df_x) < 900:\n",
    "    if i == 0:\n",
    "        sample_index = np.random.randint(0, len(dfx_whole), 10)\n",
    "        select_x = dfx_whole.iloc[sample_index].reset_index(drop=True)\n",
    "        select_y = dfy_whole.iloc[sample_index].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "        #drop selected index in the whole dataset\n",
    "        dfx_whole = dfx_whole.drop(dfx_whole.index[sample_index])\n",
    "        dfy_whole = dfy_whole.drop(dfy_whole.index[sample_index])\n",
    "    \n",
    "    if i != 0:\n",
    "            new_x = dfx_whole.sample(n=10, replace=False, random_state = None, axis=0)\n",
    "            sample_index = np.array(new_x.index)\n",
    "    df_x = pd.concat([df_x, select_x] ,axis=0, ignore_index=True)\n",
    "    df_y = pd.concat([df_y, select_y] ,axis=0, ignore_index=True)\n",
    "    list_data_x.append(df_x)\n",
    "    list_data_y.append(df_y)\n",
    "#     print(len(df_x), len(df_y))\n",
    "    \n",
    "    #drop selected index in the whole dataset\n",
    "    dfx_whole = dfx_whole.reset_index(drop=True)\n",
    "    dfy_whole = dfy_whole.reset_index(drop=True)\n",
    "    df_x = df_x.reset_index(drop=True)\n",
    "    df_y = df_y.reset_index(drop=True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "d7c4501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(x_train, y_train, x_test,y_test):\n",
    "    errors = []\n",
    "    for i in range(90):\n",
    "        c_range= [10**c for c in np.arange(-3,7, dtype=float)]\n",
    "        params = {'C':c_range}\n",
    "        Linear_SVC = LinearSVC(penalty = 'l1', dual=False, random_state = 42)\n",
    "        clf = GridSearchCV(Linear_SVC, params, cv=5)\n",
    "        clf.fit(x_train[i], y_train[i])\n",
    "        best_C = clf.best_params_['C']\n",
    "\n",
    "        # Refit the model with the best params\n",
    "        svc = LinearSVC(penalty='l1', dual=False, C=best_C)\n",
    "        svc.fit(x_train[i], y_train[i])\n",
    "        \n",
    "        errors.append(1-svc.score(x_test, y_test))\n",
    "#     print(errors[0])\n",
    "    return errors\n",
    "# errors = SVM(list_data_x, list_data_y, x_test, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "c3771e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 0\n",
      "0.07203389830508478\n",
      "\n",
      "\n",
      "m = 1\n",
      "0.14194915254237284\n",
      "\n",
      "\n",
      "m = 2\n",
      "0.14406779661016944\n",
      "\n",
      "\n",
      "m = 3\n",
      "0.15254237288135597\n",
      "\n",
      "\n",
      "m = 4\n",
      "0.10805084745762716\n",
      "\n",
      "\n",
      "m = 5\n",
      "0.15466101694915257\n",
      "\n",
      "\n",
      "m = 6\n",
      "0.14194915254237284\n",
      "\n",
      "\n",
      "m = 7\n",
      "0.05084745762711862\n",
      "\n",
      "\n",
      "m = 8\n",
      "0.15254237288135597\n",
      "\n",
      "\n",
      "m = 9\n",
      "0.1313559322033898\n",
      "\n",
      "\n",
      "m = 10\n",
      "0.14194915254237284\n",
      "\n",
      "\n",
      "m = 11\n",
      "0.15677966101694918\n",
      "\n",
      "\n",
      "m = 12\n",
      "0.07838983050847459\n",
      "\n",
      "\n",
      "m = 13\n",
      "0.12076271186440679\n",
      "\n",
      "\n",
      "m = 14\n",
      "0.09957627118644063\n",
      "\n",
      "\n",
      "m = 15\n",
      "0.07838983050847459\n",
      "\n",
      "\n",
      "m = 16\n",
      "0.08898305084745761\n",
      "\n",
      "\n",
      "m = 17\n",
      "0.03813559322033899\n",
      "\n",
      "\n",
      "m = 18\n",
      "0.052966101694915224\n",
      "\n",
      "\n",
      "m = 19\n",
      "0.10593220338983056\n",
      "\n",
      "\n",
      "m = 20\n",
      "0.1292372881355932\n",
      "\n",
      "\n",
      "m = 21\n",
      "0.18855932203389836\n",
      "\n",
      "\n",
      "m = 22\n",
      "0.1313559322033898\n",
      "\n",
      "\n",
      "m = 23\n",
      "0.0423728813559322\n",
      "\n",
      "\n",
      "m = 24\n",
      "0.0423728813559322\n",
      "\n",
      "\n",
      "m = 25\n",
      "0.11864406779661019\n",
      "\n",
      "\n",
      "m = 26\n",
      "0.10805084745762716\n",
      "\n",
      "\n",
      "m = 27\n",
      "0.31567796610169496\n",
      "\n",
      "\n",
      "m = 28\n",
      "0.14194915254237284\n",
      "\n",
      "\n",
      "m = 29\n",
      "0.25\n",
      "\n",
      "\n",
      "m = 30\n",
      "0.13347457627118642\n",
      "\n",
      "\n",
      "m = 31\n",
      "0.1610169491525424\n",
      "\n",
      "\n",
      "m = 32\n",
      "0.17796610169491522\n",
      "\n",
      "\n",
      "m = 33\n",
      "0.1716101694915254\n",
      "\n",
      "\n",
      "m = 34\n",
      "0.021186440677966156\n",
      "\n",
      "\n",
      "m = 35\n",
      "0.11440677966101698\n",
      "\n",
      "\n",
      "m = 36\n",
      "0.1652542372881356\n",
      "\n",
      "\n",
      "m = 37\n",
      "0.18008474576271183\n",
      "\n",
      "\n",
      "m = 38\n",
      "0.07838983050847459\n",
      "\n",
      "\n",
      "m = 39\n",
      "0.35169491525423724\n",
      "\n",
      "\n",
      "m = 40\n",
      "0.11228813559322037\n",
      "\n",
      "\n",
      "m = 41\n",
      "0.18855932203389836\n",
      "\n",
      "\n",
      "m = 42\n",
      "0.0805084745762712\n",
      "\n",
      "\n",
      "m = 43\n",
      "0.14618644067796616\n",
      "\n",
      "\n",
      "m = 44\n",
      "0.18855932203389836\n",
      "\n",
      "\n",
      "m = 45\n",
      "0.1673728813559322\n",
      "\n",
      "\n",
      "m = 46\n",
      "0.15254237288135597\n",
      "\n",
      "\n",
      "m = 47\n",
      "0.016949152542372836\n",
      "\n",
      "\n",
      "m = 48\n",
      "0.1610169491525424\n",
      "\n",
      "\n",
      "m = 49\n",
      "0.03389830508474578\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passive_error_list = {}\n",
    "for i in range(50):\n",
    "    a = SVM(list_data_x, list_data_y, x_test, y_test)\n",
    "    passive_error_list[i] = a \n",
    "    print('m =', i)\n",
    "    print(a[0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "e4f02b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.063559</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.074153</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.108051</td>\n",
       "      <td>0.114407</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.154661</td>\n",
       "      <td>0.154661</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.074153</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.131356</td>\n",
       "      <td>0.461864</td>\n",
       "      <td>0.180085</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.156780</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.156780</td>\n",
       "      <td>0.156780</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.120763</td>\n",
       "      <td>0.120763</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.099576</td>\n",
       "      <td>0.099576</td>\n",
       "      <td>0.114407</td>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.156780</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.131356</td>\n",
       "      <td>0.131356</td>\n",
       "      <td>0.146186</td>\n",
       "      <td>0.184322</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.108051</td>\n",
       "      <td>0.108051</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.063559</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.315678</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.209746</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.055085</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.137712</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.154661</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.114407</td>\n",
       "      <td>0.114407</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.165254</td>\n",
       "      <td>0.165254</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.180085</td>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.351695</td>\n",
       "      <td>0.351695</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.120763</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.112288</td>\n",
       "      <td>0.112288</td>\n",
       "      <td>0.063559</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.091102</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.146186</td>\n",
       "      <td>0.146186</td>\n",
       "      <td>0.099576</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.188559</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.167373</td>\n",
       "      <td>0.167373</td>\n",
       "      <td>0.158898</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.288136</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.072034  0.072034  0.063559  0.027542  0.021186  0.023305  0.023305   \n",
       "1   0.141949  0.141949  0.141949  0.086864  0.031780  0.021186  0.025424   \n",
       "2   0.144068  0.144068  0.118644  0.105932  0.074153  0.093220  0.021186   \n",
       "3   0.152542  0.152542  0.027542  0.027542  0.029661  0.027542  0.023305   \n",
       "4   0.108051  0.114407  0.125000  0.052966  0.019068  0.010593  0.014831   \n",
       "5   0.154661  0.154661  0.012712  0.021186  0.023305  0.023305  0.021186   \n",
       "6   0.141949  0.078390  0.019068  0.021186  0.021186  0.029661  0.021186   \n",
       "7   0.050847  0.044492  0.116525  0.027542  0.074153  0.057203  0.057203   \n",
       "8   0.152542  0.152542  0.031780  0.031780  0.014831  0.046610  0.014831   \n",
       "9   0.131356  0.461864  0.180085  0.014831  0.019068  0.019068  0.014831   \n",
       "10  0.141949  0.141949  0.156780  0.093220  0.080508  0.091102  0.010593   \n",
       "11  0.156780  0.156780  0.027542  0.025424  0.038136  0.021186  0.021186   \n",
       "12  0.078390  0.078390  0.016949  0.050847  0.016949  0.012712  0.008475   \n",
       "13  0.120763  0.120763  0.033898  0.021186  0.010593  0.008475  0.080508   \n",
       "14  0.099576  0.099576  0.114407  0.072034  0.093220  0.078390  0.078390   \n",
       "15  0.078390  0.129237  0.156780  0.027542  0.023305  0.046610  0.023305   \n",
       "16  0.088983  0.076271  0.059322  0.019068  0.033898  0.046610  0.014831   \n",
       "17  0.038136  0.038136  0.021186  0.019068  0.021186  0.027542  0.023305   \n",
       "18  0.052966  0.086864  0.065678  0.010593  0.019068  0.019068  0.008475   \n",
       "19  0.105932  0.105932  0.133475  0.025424  0.023305  0.021186  0.016949   \n",
       "20  0.129237  0.129237  0.084746  0.078390  0.010593  0.010593  0.010593   \n",
       "21  0.188559  0.188559  0.027542  0.027542  0.027542  0.027542  0.027542   \n",
       "22  0.131356  0.131356  0.146186  0.184322  0.052966  0.029661  0.029661   \n",
       "23  0.042373  0.042373  0.105932  0.050847  0.029661  0.044492  0.029661   \n",
       "24  0.042373  0.042373  0.025424  0.021186  0.016949  0.021186  0.016949   \n",
       "25  0.118644  0.088983  0.025424  0.021186  0.023305  0.019068  0.012712   \n",
       "26  0.108051  0.108051  0.097458  0.086864  0.063559  0.065678  0.080508   \n",
       "27  0.315678  0.144068  0.086864  0.012712  0.021186  0.025424  0.033898   \n",
       "28  0.141949  0.141949  0.101695  0.116525  0.012712  0.019068  0.021186   \n",
       "29  0.250000  0.209746  0.093220  0.042373  0.078390  0.036017  0.069915   \n",
       "30  0.133475  0.133475  0.137712  0.021186  0.019068  0.021186  0.014831   \n",
       "31  0.161017  0.161017  0.161017  0.023305  0.023305  0.031780  0.029661   \n",
       "32  0.177966  0.154661  0.027542  0.025424  0.019068  0.021186  0.023305   \n",
       "33  0.171610  0.171610  0.021186  0.021186  0.019068  0.019068  0.016949   \n",
       "34  0.021186  0.021186  0.029661  0.036017  0.025424  0.027542  0.027542   \n",
       "35  0.114407  0.114407  0.076271  0.016949  0.012712  0.012712  0.012712   \n",
       "36  0.165254  0.165254  0.023305  0.016949  0.025424  0.010593  0.033898   \n",
       "37  0.180085  0.105932  0.080508  0.080508  0.076271  0.057203  0.027542   \n",
       "38  0.078390  0.078390  0.027542  0.029661  0.029661  0.029661  0.016949   \n",
       "39  0.351695  0.351695  0.084746  0.127119  0.120763  0.038136  0.021186   \n",
       "40  0.112288  0.112288  0.063559  0.031780  0.010593  0.014831  0.019068   \n",
       "41  0.188559  0.186441  0.188559  0.072034  0.052966  0.052966  0.029661   \n",
       "42  0.080508  0.091102  0.118644  0.067797  0.027542  0.023305  0.016949   \n",
       "43  0.146186  0.146186  0.099576  0.088983  0.023305  0.029661  0.021186   \n",
       "44  0.188559  0.188559  0.052966  0.082627  0.029661  0.019068  0.019068   \n",
       "45  0.167373  0.167373  0.158898  0.065678  0.031780  0.012712  0.088983   \n",
       "46  0.152542  0.288136  0.059322  0.036017  0.069915  0.067797  0.057203   \n",
       "47  0.016949  0.016949  0.038136  0.031780  0.025424  0.025424  0.019068   \n",
       "48  0.161017  0.161017  0.101695  0.014831  0.014831  0.019068  0.014831   \n",
       "49  0.033898  0.033898  0.118644  0.057203  0.021186  0.021186  0.016949   \n",
       "\n",
       "          7         8         9   ...        80        81        82        83  \\\n",
       "0   0.021186  0.025424  0.027542  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "1   0.023305  0.023305  0.027542  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "2   0.019068  0.023305  0.025424  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "3   0.021186  0.027542  0.025424  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "4   0.014831  0.014831  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "5   0.031780  0.027542  0.027542  ...  0.008475  0.012712  0.012712  0.012712   \n",
       "6   0.027542  0.012712  0.029661  ...  0.014831  0.016949  0.014831  0.014831   \n",
       "7   0.016949  0.012712  0.010593  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "8   0.008475  0.014831  0.010593  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "9   0.014831  0.010593  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "10  0.016949  0.016949  0.016949  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "11  0.021186  0.021186  0.021186  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "12  0.008475  0.008475  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "13  0.010593  0.004237  0.069915  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "14  0.105932  0.033898  0.052966  ...  0.016949  0.019068  0.019068  0.016949   \n",
       "15  0.023305  0.021186  0.016949  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "16  0.025424  0.016949  0.016949  ...  0.008475  0.008475  0.012712  0.008475   \n",
       "17  0.025424  0.021186  0.019068  ...  0.008475  0.008475  0.008475  0.010593   \n",
       "18  0.008475  0.008475  0.010593  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "19  0.016949  0.014831  0.014831  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "20  0.008475  0.010593  0.010593  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "21  0.027542  0.021186  0.023305  ...  0.012712  0.019068  0.012712  0.012712   \n",
       "22  0.036017  0.025424  0.014831  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "23  0.012712  0.027542  0.027542  ...  0.008475  0.012712  0.008475  0.008475   \n",
       "24  0.016949  0.016949  0.016949  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "25  0.014831  0.014831  0.023305  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "26  0.080508  0.023305  0.008475  ...  0.012712  0.008475  0.008475  0.008475   \n",
       "27  0.016949  0.031780  0.031780  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "28  0.021186  0.019068  0.014831  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "29  0.055085  0.023305  0.080508  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "30  0.008475  0.008475  0.023305  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "31  0.027542  0.027542  0.012712  ...  0.008475  0.006356  0.008475  0.008475   \n",
       "32  0.023305  0.025424  0.021186  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "33  0.016949  0.021186  0.014831  ...  0.008475  0.008475  0.012712  0.012712   \n",
       "34  0.025424  0.027542  0.033898  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "35  0.012712  0.014831  0.012712  ...  0.006356  0.006356  0.008475  0.008475   \n",
       "36  0.029661  0.021186  0.025424  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "37  0.027542  0.023305  0.021186  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "38  0.008475  0.006356  0.008475  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "39  0.021186  0.021186  0.025424  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "40  0.021186  0.021186  0.021186  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "41  0.016949  0.023305  0.019068  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "42  0.016949  0.016949  0.021186  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "43  0.025424  0.016949  0.019068  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "44  0.014831  0.014831  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "45  0.014831  0.012712  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "46  0.052966  0.044492  0.031780  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "47  0.021186  0.021186  0.016949  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "48  0.014831  0.010593  0.010593  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "49  0.012712  0.019068  0.021186  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "\n",
       "          84        85        86        87        88        89  \n",
       "0   0.012712  0.012712  0.008475  0.008475  0.008475  0.008475  \n",
       "1   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "2   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "3   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "4   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "5   0.012712  0.012712  0.012712  0.008475  0.008475  0.008475  \n",
       "6   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "7   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "8   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "9   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "10  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "11  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "12  0.012712  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "13  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "14  0.016949  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "15  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "16  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "17  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "18  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "19  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "20  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "21  0.019068  0.014831  0.008475  0.008475  0.008475  0.008475  \n",
       "22  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "23  0.012712  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "24  0.008475  0.008475  0.008475  0.008475  0.012712  0.012712  \n",
       "25  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "26  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "27  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "28  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "29  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "30  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "31  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "32  0.012712  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "33  0.012712  0.012712  0.008475  0.008475  0.008475  0.008475  \n",
       "34  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "35  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "36  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "37  0.008475  0.008475  0.008475  0.008475  0.012712  0.012712  \n",
       "38  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "39  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "40  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "41  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "42  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "43  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "44  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "45  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "46  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "47  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "48  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "49  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "\n",
       "[50 rows x 90 columns]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(passive_error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51114db",
   "metadata": {},
   "source": [
    "#### ii.Train a SVM with a pool of 10 randomly selected data points from the training set using linear kernel andL1 penalty. Select the parameters of the SVM with 5-fold cross validation. Choose the 10 closest data points in the training set to the hyperplane of the SVM and add them to the pool. Do not replace the samples back into the training set. Train a new SVM using the pool. Repeat this process until all training data is used. You will have 90 SVMs that were trained using 10, 20, 30,..., 900 data points and their 90 test errors.You have implemented active learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "e87f8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active(x_train, y_train, x_test, y_test):\n",
    "    df_new = pd.concat([x_train,y_train])\n",
    "    select_x = pd.DataFrame()\n",
    "    select_y = pd.DataFrame()\n",
    "    dfx_whole = x_train.copy()\n",
    "    dfy_whole = y_train.copy()\n",
    "    list_data_x = []\n",
    "    list_data_y = []\n",
    "    while len(select_x) < 1:\n",
    "        sample_index = np.random.randint(0, len(dfx_whole), 10)\n",
    "        select_x = dfx_whole.iloc[sample_index]\n",
    "        select_y = dfy_whole.iloc[sample_index]\n",
    "    select_x = select_x.reset_index(drop=True)\n",
    "    select_y = select_y.reset_index(drop=True)\n",
    "    #drop selected index in the whole dataset\n",
    "    dfx_whole = dfx_whole.drop(dfx_whole.index[sample_index])\n",
    "    dfy_whole = dfy_whole.drop(dfy_whole.index[sample_index])\n",
    "    \n",
    "    \n",
    "    dfx_whole = dfx_whole.reset_index(drop=True)\n",
    "    dfy_whole = dfy_whole.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    errors = []\n",
    "    for i in range(90):\n",
    "        c_range= [10**c for c in np.arange(-3,7, dtype=float)]\n",
    "        params = {'C':c_range}\n",
    "        Linear_SVC = LinearSVC(penalty = 'l1', dual=False, random_state = 42)\n",
    "        clf = GridSearchCV(Linear_SVC, params, cv=5)\n",
    "        clf.fit(select_x, select_y)\n",
    "        best_C = clf.best_params_['C']\n",
    "\n",
    "        # Refit the model with the best params\n",
    "        svc = LinearSVC(penalty='l1', dual=False, C=best_C)\n",
    "        svc.fit(select_x, select_y)\n",
    "        \n",
    "        errors.append(1-svc.score(x_test, y_test))\n",
    "        \n",
    "        if i > 0:\n",
    "            distances = svc.decision_function(dfx_whole)\n",
    "            sample_index = np.argsort(abs(distances))[:10]\n",
    "        \n",
    "            select_x = pd.concat([select_x, dfx_whole.iloc[sample_index]],axis=0, ignore_index=True)\n",
    "            select_y = pd.concat([select_y, dfy_whole.iloc[sample_index]],axis=0, ignore_index=True)\n",
    "            # drop selected indexes\n",
    "            dfx_whole = dfx_whole.drop(dfx_whole.index[sample_index])\n",
    "            dfy_whole = dfy_whole.drop(dfy_whole.index[sample_index])\n",
    "            #reset index\n",
    "            dfx_whole = dfx_whole.reset_index(drop=True)\n",
    "            dfy_whole = dfy_whole.reset_index(drop=True)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "52af3cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 0\n",
      "0.1292372881355932\n",
      "\n",
      "\n",
      "m = 1\n",
      "0.05508474576271183\n",
      "\n",
      "\n",
      "m = 2\n",
      "0.14406779661016944\n",
      "\n",
      "\n",
      "m = 3\n",
      "0.13771186440677963\n",
      "\n",
      "\n",
      "m = 4\n",
      "0.0826271186440678\n",
      "\n",
      "\n",
      "m = 5\n",
      "0.0423728813559322\n",
      "\n",
      "\n",
      "m = 6\n",
      "0.03601694915254239\n",
      "\n",
      "\n",
      "m = 7\n",
      "0.1716101694915254\n",
      "\n",
      "\n",
      "m = 8\n",
      "0.13983050847457623\n",
      "\n",
      "\n",
      "m = 9\n",
      "0.1271186440677966\n",
      "\n",
      "\n",
      "m = 10\n",
      "0.1271186440677966\n",
      "\n",
      "\n",
      "m = 11\n",
      "0.10381355932203384\n",
      "\n",
      "\n",
      "m = 12\n",
      "0.11440677966101698\n",
      "\n",
      "\n",
      "m = 13\n",
      "0.14194915254237284\n",
      "\n",
      "\n",
      "m = 14\n",
      "0.44491525423728817\n",
      "\n",
      "\n",
      "m = 15\n",
      "0.11652542372881358\n",
      "\n",
      "\n",
      "m = 16\n",
      "0.07203389830508478\n",
      "\n",
      "\n",
      "m = 17\n",
      "0.13347457627118642\n",
      "\n",
      "\n",
      "m = 18\n",
      "0.2838983050847458\n",
      "\n",
      "\n",
      "m = 19\n",
      "0.14406779661016944\n",
      "\n",
      "\n",
      "m = 20\n",
      "0.11228813559322037\n",
      "\n",
      "\n",
      "m = 21\n",
      "0.03601694915254239\n",
      "\n",
      "\n",
      "m = 22\n",
      "0.44491525423728817\n",
      "\n",
      "\n",
      "m = 23\n",
      "0.44491525423728817\n",
      "\n",
      "\n",
      "m = 24\n",
      "0.06567796610169496\n",
      "\n",
      "\n",
      "m = 25\n",
      "0.1228813559322034\n",
      "\n",
      "\n",
      "m = 26\n",
      "0.09533898305084743\n",
      "\n",
      "\n",
      "m = 27\n",
      "0.11652542372881358\n",
      "\n",
      "\n",
      "m = 28\n",
      "0.08686440677966101\n",
      "\n",
      "\n",
      "m = 29\n",
      "0.163135593220339\n",
      "\n",
      "\n",
      "m = 30\n",
      "0.0826271186440678\n",
      "\n",
      "\n",
      "m = 31\n",
      "0.336864406779661\n",
      "\n",
      "\n",
      "m = 32\n",
      "0.14406779661016944\n",
      "\n",
      "\n",
      "m = 33\n",
      "0.3707627118644068\n",
      "\n",
      "\n",
      "m = 34\n",
      "0.13559322033898302\n",
      "\n",
      "\n",
      "m = 35\n",
      "0.11652542372881358\n",
      "\n",
      "\n",
      "m = 36\n",
      "0.03177966101694918\n",
      "\n",
      "\n",
      "m = 37\n",
      "0.014830508474576232\n",
      "\n",
      "\n",
      "m = 38\n",
      "0.125\n",
      "\n",
      "\n",
      "m = 39\n",
      "0.11652542372881358\n",
      "\n",
      "\n",
      "m = 40\n",
      "0.15254237288135597\n",
      "\n",
      "\n",
      "m = 41\n",
      "0.08898305084745761\n",
      "\n",
      "\n",
      "m = 42\n",
      "0.26483050847457623\n",
      "\n",
      "\n",
      "m = 43\n",
      "0.21610169491525422\n",
      "\n",
      "\n",
      "m = 44\n",
      "0.15042372881355937\n",
      "\n",
      "\n",
      "m = 45\n",
      "0.23940677966101698\n",
      "\n",
      "\n",
      "m = 46\n",
      "0.025423728813559365\n",
      "\n",
      "\n",
      "m = 47\n",
      "0.03389830508474578\n",
      "\n",
      "\n",
      "m = 48\n",
      "0.13559322033898302\n",
      "\n",
      "\n",
      "m = 49\n",
      "0.11652542372881358\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turn2 = list()\n",
    "for i in range(50):\n",
    "    b = active(x_train, y_train, x_test, y_test)\n",
    "    turn2.append(b)\n",
    "    print('m =', i)\n",
    "    print(b[0])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "33adc5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055085</td>\n",
       "      <td>0.055085</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.055085</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.137712</td>\n",
       "      <td>0.137712</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.171610</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.139831</td>\n",
       "      <td>0.139831</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.127119</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.103814</td>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.114407</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.057203</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.141949</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.444915</td>\n",
       "      <td>0.444915</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.283898</td>\n",
       "      <td>0.283898</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.209746</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.112288</td>\n",
       "      <td>0.112288</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.444915</td>\n",
       "      <td>0.444915</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.444915</td>\n",
       "      <td>0.444915</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.074153</td>\n",
       "      <td>0.055085</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.122881</td>\n",
       "      <td>0.122881</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.095339</td>\n",
       "      <td>0.095339</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.086864</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.163136</td>\n",
       "      <td>0.163136</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.061441</td>\n",
       "      <td>0.038136</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.105932</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.336864</td>\n",
       "      <td>0.336864</td>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.055085</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.370763</td>\n",
       "      <td>0.370763</td>\n",
       "      <td>0.110169</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.165254</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.163136</td>\n",
       "      <td>0.129237</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.131356</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.063559</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.078390</td>\n",
       "      <td>0.061441</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.264831</td>\n",
       "      <td>0.264831</td>\n",
       "      <td>0.061441</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.216102</td>\n",
       "      <td>0.216102</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.150424</td>\n",
       "      <td>0.150424</td>\n",
       "      <td>0.046610</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.239407</td>\n",
       "      <td>0.239407</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.036017</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.044492</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.129237  0.129237  0.042373  0.038136  0.023305  0.019068  0.012712   \n",
       "1   0.055085  0.055085  0.019068  0.019068  0.008475  0.008475  0.008475   \n",
       "2   0.144068  0.144068  0.055085  0.033898  0.021186  0.012712  0.023305   \n",
       "3   0.137712  0.137712  0.031780  0.129237  0.023305  0.069915  0.025424   \n",
       "4   0.082627  0.088983  0.033898  0.025424  0.006356  0.008475  0.006356   \n",
       "5   0.042373  0.042373  0.038136  0.008475  0.008475  0.078390  0.016949   \n",
       "6   0.036017  0.036017  0.023305  0.050847  0.019068  0.014831  0.010593   \n",
       "7   0.171610  0.171610  0.008475  0.069915  0.038136  0.029661  0.021186   \n",
       "8   0.139831  0.139831  0.036017  0.008475  0.008475  0.014831  0.012712   \n",
       "9   0.127119  0.127119  0.029661  0.012712  0.019068  0.008475  0.008475   \n",
       "10  0.127119  0.127119  0.042373  0.033898  0.008475  0.008475  0.012712   \n",
       "11  0.103814  0.105932  0.046610  0.023305  0.052966  0.019068  0.014831   \n",
       "12  0.114407  0.116525  0.057203  0.023305  0.023305  0.012712  0.008475   \n",
       "13  0.141949  0.141949  0.052966  0.023305  0.023305  0.016949  0.008475   \n",
       "14  0.444915  0.444915  0.059322  0.012712  0.052966  0.038136  0.029661   \n",
       "15  0.116525  0.116525  0.027542  0.023305  0.038136  0.012712  0.016949   \n",
       "16  0.072034  0.072034  0.031780  0.021186  0.012712  0.012712  0.008475   \n",
       "17  0.133475  0.133475  0.042373  0.016949  0.014831  0.010593  0.012712   \n",
       "18  0.283898  0.283898  0.076271  0.016949  0.059322  0.012712  0.016949   \n",
       "19  0.144068  0.209746  0.050847  0.050847  0.012712  0.016949  0.019068   \n",
       "20  0.112288  0.112288  0.046610  0.016949  0.019068  0.014831  0.027542   \n",
       "21  0.036017  0.036017  0.019068  0.016949  0.014831  0.008475  0.012712   \n",
       "22  0.444915  0.444915  0.076271  0.052966  0.042373  0.023305  0.016949   \n",
       "23  0.444915  0.444915  0.052966  0.010593  0.004237  0.006356  0.006356   \n",
       "24  0.065678  0.074153  0.055085  0.023305  0.008475  0.008475  0.008475   \n",
       "25  0.122881  0.122881  0.080508  0.052966  0.027542  0.023305  0.008475   \n",
       "26  0.095339  0.095339  0.038136  0.008475  0.023305  0.012712  0.012712   \n",
       "27  0.116525  0.116525  0.038136  0.021186  0.008475  0.021186  0.019068   \n",
       "28  0.086864  0.086864  0.019068  0.029661  0.021186  0.014831  0.012712   \n",
       "29  0.163136  0.163136  0.029661  0.078390  0.061441  0.038136  0.012712   \n",
       "30  0.082627  0.082627  0.105932  0.033898  0.029661  0.012712  0.008475   \n",
       "31  0.336864  0.336864  0.082627  0.023305  0.014831  0.012712  0.012712   \n",
       "32  0.144068  0.144068  0.029661  0.055085  0.042373  0.027542  0.025424   \n",
       "33  0.370763  0.370763  0.110169  0.021186  0.023305  0.014831  0.006356   \n",
       "34  0.135593  0.135593  0.019068  0.019068  0.016949  0.012712  0.008475   \n",
       "35  0.116525  0.116525  0.025424  0.059322  0.044492  0.010593  0.010593   \n",
       "36  0.031780  0.031780  0.165254  0.016949  0.008475  0.008475  0.008475   \n",
       "37  0.014831  0.014831  0.163136  0.129237  0.014831  0.006356  0.014831   \n",
       "38  0.125000  0.125000  0.131356  0.052966  0.033898  0.025424  0.016949   \n",
       "39  0.116525  0.116525  0.033898  0.063559  0.006356  0.025424  0.014831   \n",
       "40  0.152542  0.152542  0.036017  0.080508  0.016949  0.014831  0.014831   \n",
       "41  0.088983  0.078390  0.061441  0.027542  0.025424  0.023305  0.019068   \n",
       "42  0.264831  0.264831  0.061441  0.084746  0.025424  0.014831  0.012712   \n",
       "43  0.216102  0.216102  0.025424  0.023305  0.008475  0.014831  0.008475   \n",
       "44  0.150424  0.150424  0.046610  0.010593  0.016949  0.008475  0.012712   \n",
       "45  0.239407  0.239407  0.021186  0.036017  0.008475  0.016949  0.012712   \n",
       "46  0.025424  0.044492  0.016949  0.012712  0.008475  0.008475  0.012712   \n",
       "47  0.033898  0.033898  0.101695  0.031780  0.027542  0.004237  0.006356   \n",
       "48  0.135593  0.135593  0.014831  0.044492  0.025424  0.021186  0.023305   \n",
       "49  0.116525  0.116525  0.029661  0.033898  0.021186  0.012712  0.010593   \n",
       "\n",
       "          7         8         9   ...        80        81        82        83  \\\n",
       "0   0.012712  0.010593  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "1   0.008475  0.010593  0.012712  ...  0.008475  0.008475  0.008475  0.010593   \n",
       "2   0.021186  0.019068  0.008475  ...  0.010593  0.010593  0.010593  0.008475   \n",
       "3   0.008475  0.008475  0.008475  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "4   0.012712  0.010593  0.008475  ...  0.012712  0.012712  0.012712  0.010593   \n",
       "5   0.008475  0.010593  0.010593  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "6   0.008475  0.012712  0.008475  ...  0.010593  0.012712  0.012712  0.010593   \n",
       "7   0.016949  0.006356  0.008475  ...  0.008475  0.010593  0.008475  0.008475   \n",
       "8   0.019068  0.008475  0.012712  ...  0.012712  0.012712  0.008475  0.012712   \n",
       "9   0.010593  0.008475  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "10  0.010593  0.008475  0.012712  ...  0.008475  0.012712  0.010593  0.010593   \n",
       "11  0.008475  0.008475  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "12  0.008475  0.008475  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "13  0.012712  0.019068  0.010593  ...  0.010593  0.010593  0.010593  0.010593   \n",
       "14  0.021186  0.014831  0.016949  ...  0.010593  0.010593  0.012712  0.012712   \n",
       "15  0.008475  0.008475  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "16  0.012712  0.012712  0.008475  ...  0.012712  0.012712  0.012712  0.010593   \n",
       "17  0.008475  0.008475  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "18  0.016949  0.012712  0.021186  ...  0.012712  0.012712  0.012712  0.010593   \n",
       "19  0.012712  0.008475  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "20  0.008475  0.008475  0.008475  ...  0.012712  0.010593  0.010593  0.008475   \n",
       "21  0.021186  0.008475  0.010593  ...  0.010593  0.010593  0.010593  0.008475   \n",
       "22  0.004237  0.027542  0.012712  ...  0.010593  0.010593  0.010593  0.010593   \n",
       "23  0.012712  0.012712  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "24  0.008475  0.008475  0.010593  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "25  0.006356  0.012712  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "26  0.008475  0.008475  0.010593  ...  0.010593  0.012712  0.008475  0.010593   \n",
       "27  0.021186  0.010593  0.008475  ...  0.010593  0.010593  0.012712  0.010593   \n",
       "28  0.008475  0.008475  0.010593  ...  0.008475  0.012712  0.010593  0.010593   \n",
       "29  0.025424  0.021186  0.014831  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "30  0.008475  0.008475  0.008475  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "31  0.008475  0.008475  0.021186  ...  0.010593  0.008475  0.008475  0.008475   \n",
       "32  0.008475  0.016949  0.012712  ...  0.008475  0.010593  0.008475  0.010593   \n",
       "33  0.016949  0.012712  0.012712  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "34  0.008475  0.010593  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "35  0.008475  0.012712  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "36  0.008475  0.004237  0.010593  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "37  0.016949  0.021186  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "38  0.019068  0.008475  0.008475  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "39  0.014831  0.008475  0.008475  ...  0.010593  0.010593  0.010593  0.010593   \n",
       "40  0.012712  0.006356  0.010593  ...  0.010593  0.010593  0.012712  0.012712   \n",
       "41  0.016949  0.010593  0.012712  ...  0.008475  0.008475  0.008475  0.008475   \n",
       "42  0.012712  0.010593  0.012712  ...  0.010593  0.010593  0.010593  0.010593   \n",
       "43  0.008475  0.008475  0.012712  ...  0.010593  0.010593  0.010593  0.010593   \n",
       "44  0.008475  0.008475  0.008475  ...  0.010593  0.010593  0.012712  0.012712   \n",
       "45  0.008475  0.008475  0.008475  ...  0.012712  0.012712  0.012712  0.012712   \n",
       "46  0.008475  0.012712  0.008475  ...  0.010593  0.010593  0.012712  0.010593   \n",
       "47  0.012712  0.008475  0.012712  ...  0.012712  0.010593  0.010593  0.008475   \n",
       "48  0.021186  0.012712  0.008475  ...  0.010593  0.012712  0.012712  0.012712   \n",
       "49  0.021186  0.006356  0.012712  ...  0.008475  0.008475  0.008475  0.010593   \n",
       "\n",
       "          84        85        86        87        88        89  \n",
       "0   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "1   0.010593  0.012712  0.012712  0.010593  0.012712  0.012712  \n",
       "2   0.010593  0.008475  0.008475  0.012712  0.012712  0.008475  \n",
       "3   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "4   0.010593  0.012712  0.008475  0.008475  0.008475  0.008475  \n",
       "5   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "6   0.012712  0.010593  0.010593  0.010593  0.010593  0.012712  \n",
       "7   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "8   0.012712  0.008475  0.012712  0.008475  0.008475  0.008475  \n",
       "9   0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "10  0.010593  0.010593  0.010593  0.010593  0.012712  0.012712  \n",
       "11  0.012712  0.012712  0.010593  0.010593  0.008475  0.008475  \n",
       "12  0.012712  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "13  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "14  0.012712  0.012712  0.012712  0.012712  0.010593  0.012712  \n",
       "15  0.012712  0.012712  0.012712  0.012712  0.012712  0.012712  \n",
       "16  0.010593  0.012712  0.012712  0.008475  0.008475  0.008475  \n",
       "17  0.010593  0.012712  0.008475  0.008475  0.008475  0.008475  \n",
       "18  0.010593  0.010593  0.010593  0.008475  0.008475  0.008475  \n",
       "19  0.012712  0.010593  0.012712  0.012712  0.012712  0.012712  \n",
       "20  0.008475  0.012712  0.012712  0.008475  0.008475  0.008475  \n",
       "21  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "22  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "23  0.012712  0.010593  0.012712  0.012712  0.012712  0.012712  \n",
       "24  0.010593  0.010593  0.008475  0.008475  0.008475  0.008475  \n",
       "25  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "26  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "27  0.010593  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "28  0.012712  0.012712  0.012712  0.012712  0.012712  0.008475  \n",
       "29  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "30  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "31  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "32  0.010593  0.012712  0.012712  0.012712  0.012712  0.012712  \n",
       "33  0.012712  0.010593  0.012712  0.008475  0.012712  0.008475  \n",
       "34  0.008475  0.010593  0.010593  0.008475  0.008475  0.008475  \n",
       "35  0.012712  0.010593  0.010593  0.008475  0.008475  0.008475  \n",
       "36  0.010593  0.012712  0.012712  0.008475  0.008475  0.008475  \n",
       "37  0.012712  0.012712  0.012712  0.012712  0.012712  0.008475  \n",
       "38  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "39  0.010593  0.012712  0.012712  0.012712  0.012712  0.012712  \n",
       "40  0.012712  0.012712  0.012712  0.010593  0.010593  0.010593  \n",
       "41  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "42  0.010593  0.010593  0.008475  0.008475  0.008475  0.008475  \n",
       "43  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "44  0.012712  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "45  0.012712  0.012712  0.008475  0.008475  0.012712  0.008475  \n",
       "46  0.012712  0.012712  0.012712  0.012712  0.012712  0.012712  \n",
       "47  0.008475  0.008475  0.008475  0.008475  0.012712  0.012712  \n",
       "48  0.012712  0.010593  0.010593  0.012712  0.008475  0.008475  \n",
       "49  0.008475  0.008475  0.008475  0.008475  0.008475  0.008475  \n",
       "\n",
       "[50 rows x 90 columns]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(turn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb30bca",
   "metadata": {},
   "source": [
    "#### c)Average the 50 test errors for each of the incrementally trained 90 SVMs in 2(b)i and 2(b)ii. By doing so, you are performing a Monte Carlo simulation. Plot average test error versus number of training instances for both active and passive learners on the same figure and report your conclusions. Here, you are actually obtaining a learning curve by Monte-Carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "f17eb4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "range_plt = np.arange(10, 910, 10)\n",
    "plt.plot(range_plt, pd.DataFrame(passive_error_list).mean() ,label='Passive Learning')\n",
    "plt.plot(range_plt, pd.DataFrame(turn2).mean(), c='r', label='Active Learning')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d885910",
   "metadata": {},
   "source": [
    "Conclusion: We can see from the graph that passive learning has better performance when the size of the trainind data is small. As the size become large, the passvie and active learning will have same performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e222ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
