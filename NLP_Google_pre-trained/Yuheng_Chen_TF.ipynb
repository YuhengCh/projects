{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqYTkwGy6d0z",
        "outputId": "13855df2-9c37-44f9-f7b6-a21f97cfe518"
      },
      "id": "NqYTkwGy6d0z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZeYyWZC614s",
        "outputId": "164f0514-a630-444a-b8c8-f47a2c2657b5"
      },
      "id": "8ZeYyWZC614s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.8/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.8/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c399e0c",
      "metadata": {
        "id": "7c399e0c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import contractions\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim.models\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "import tensorflow as tf\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.layers import Dense, Embedding, LSTM, Flatten, Dropout, Conv2D, MaxPooling2D\n",
        "from keras import Input\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvarLJH-6cfp"
      },
      "id": "yvarLJH-6cfp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5546c35a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5546c35a",
        "outputId": "98071d05-96ab-4a2f-90a1-82a41d077795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11442f02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11442f02",
        "outputId": "0b6fcf83-643f-46ae-8585-989753d612b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (4.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: FuzzyTM>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (2.0.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (1.3.5)\n",
            "Requirement already satisfied: pyfume in /usr/local/lib/python3.8/dist-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7.1)\n",
            "Requirement already satisfied: simpful in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.10.0)\n",
            "Requirement already satisfied: fst-pso in /usr/local/lib/python3.8/dist-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.15.0)\n",
            "Requirement already satisfied: miniful in /usr/local/lib/python3.8/dist-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.10)\n"
          ]
        }
      ],
      "source": [
        "pip install -U gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea5d8f0b",
      "metadata": {
        "id": "ea5d8f0b"
      },
      "source": [
        "## 1. Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbbe1fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "fcbbe1fc",
        "outputId": "13c56dcc-a090-4cb1-e2b1-73a638a1d393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
              "0                US      1797882  R3I2DHQBR577SS  B001ANOOOE         2102612   \n",
              "1                US     18381298  R1QNE9NQFJC2Y4  B0016J22EQ       106393691   \n",
              "2                US     19242472  R3LIDG2Q4LJBAO  B00HU6UQAG       375449471   \n",
              "3                US     19551372  R3KSZHPAEVPEAL  B002HWS7RM       255651889   \n",
              "4                US     14802407   RAI2OIG50KZ43  B00SM99KWU       116158747   \n",
              "...             ...          ...             ...         ...             ...   \n",
              "5087968          US     29399262  R2AEH9L5PCOL0C  B000620OGC       531618700   \n",
              "5087969          US     38881154  R29TN19DCVI44R  B000052YHS       397259610   \n",
              "5087970          US     14626862   R2X1AWYK6MGBE  B0002I3ZNO       833332489   \n",
              "5087971          US     35142523  R1L6C2F1ZB6YKT  B000063XHQ       442263387   \n",
              "5087972          US     43699244  R1NH7XPY9N2EIS  B0001HYJW2       625583359   \n",
              "\n",
              "                                             product_title product_category  \\\n",
              "0        The Naked Bee Vitmin C Moisturizing Sunscreen ...           Beauty   \n",
              "1            Alba Botanica Sunless Tanning Lotion, 4 Ounce           Beauty   \n",
              "2                Elysee Infusion Skin Therapy Elixir, 2oz.           Beauty   \n",
              "3        Diane D722 Color, Perm And Conditioner Process...           Beauty   \n",
              "4        Biore UV Aqua Rich Watery Essence SPF50+/PA+++...           Beauty   \n",
              "...                                                    ...              ...   \n",
              "5087968  Avon Advance Techniques Straight & Sleek Dry E...           Beauty   \n",
              "5087969   Gillette Mach3 Men's Razor, Mens Razors / Blades           Beauty   \n",
              "5087970  V'Tae Oatmeal Silk Bath, Healing Therapy, 6-Ou...           Beauty   \n",
              "5087971        Panasonic ER411NC Nose and Ear Hair Groomer           Beauty   \n",
              "5087972  Philips Norelco T970 Accu-Vac Beard and Mousta...           Beauty   \n",
              "\n",
              "        star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
              "0                 5            0.0          0.0    N                 Y   \n",
              "1                 5            0.0          0.0    N                 Y   \n",
              "2                 5            0.0          0.0    N                 Y   \n",
              "3                 5            0.0          0.0    N                 Y   \n",
              "4                 5            0.0          0.0    N                 Y   \n",
              "...             ...            ...          ...  ...               ...   \n",
              "5087968           1            1.0          5.0    N                 N   \n",
              "5087969           4            1.0          1.0    N                 N   \n",
              "5087970           5            0.0          0.0    N                 N   \n",
              "5087971           5            2.0          9.0    N                 N   \n",
              "5087972           2            5.0          8.0    N                 N   \n",
              "\n",
              "                                           review_headline  \\\n",
              "0                                               Five Stars   \n",
              "1                                Thank you Alba Bontanica!   \n",
              "2                                               Five Stars   \n",
              "3                                               GOOD DEAL!   \n",
              "4        this soaks in quick and provides a nice base f...   \n",
              "...                                                    ...   \n",
              "5087968           Use only if you want Oily feel like hair   \n",
              "5087969                                        Good but...   \n",
              "5087970                                           soothing   \n",
              "5087971                       embarrassing gift, but great   \n",
              "5087972                                        Unfortunate   \n",
              "\n",
              "                                               review_body review_date  \n",
              "0                         Love this, excellent sun block!!  2015-08-31  \n",
              "1        The great thing about this cream is that it do...  2015-08-31  \n",
              "2        Great Product, I'm 65 years old and this is al...  2015-08-31  \n",
              "3        I use them as shower caps & conditioning caps....  2015-08-31  \n",
              "4        This is my go-to daily sunblock. It leaves no ...  2015-08-31  \n",
              "...                                                    ...         ...  \n",
              "5087968  I tried this stuff and it made my hair feel oi...  2005-02-03  \n",
              "5087969  This is an extremely good razor.  It definitel...  2005-02-03  \n",
              "5087970  I bought this because I have extremely dry sen...  2005-02-03  \n",
              "5087971  Buy it for yourself. It's less than $15, and *...  2005-02-03  \n",
              "5087972  I've been using the Norelco series for about 5...         NaN  \n",
              "\n",
              "[5087973 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-babe7f30-12a6-40a0-bfac-e3688181145c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>1797882</td>\n",
              "      <td>R3I2DHQBR577SS</td>\n",
              "      <td>B001ANOOOE</td>\n",
              "      <td>2102612</td>\n",
              "      <td>The Naked Bee Vitmin C Moisturizing Sunscreen ...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Love this, excellent sun block!!</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>18381298</td>\n",
              "      <td>R1QNE9NQFJC2Y4</td>\n",
              "      <td>B0016J22EQ</td>\n",
              "      <td>106393691</td>\n",
              "      <td>Alba Botanica Sunless Tanning Lotion, 4 Ounce</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Thank you Alba Bontanica!</td>\n",
              "      <td>The great thing about this cream is that it do...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>19242472</td>\n",
              "      <td>R3LIDG2Q4LJBAO</td>\n",
              "      <td>B00HU6UQAG</td>\n",
              "      <td>375449471</td>\n",
              "      <td>Elysee Infusion Skin Therapy Elixir, 2oz.</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>19551372</td>\n",
              "      <td>R3KSZHPAEVPEAL</td>\n",
              "      <td>B002HWS7RM</td>\n",
              "      <td>255651889</td>\n",
              "      <td>Diane D722 Color, Perm And Conditioner Process...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>GOOD DEAL!</td>\n",
              "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>14802407</td>\n",
              "      <td>RAI2OIG50KZ43</td>\n",
              "      <td>B00SM99KWU</td>\n",
              "      <td>116158747</td>\n",
              "      <td>Biore UV Aqua Rich Watery Essence SPF50+/PA+++...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>this soaks in quick and provides a nice base f...</td>\n",
              "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087968</th>\n",
              "      <td>US</td>\n",
              "      <td>29399262</td>\n",
              "      <td>R2AEH9L5PCOL0C</td>\n",
              "      <td>B000620OGC</td>\n",
              "      <td>531618700</td>\n",
              "      <td>Avon Advance Techniques Straight &amp; Sleek Dry E...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Use only if you want Oily feel like hair</td>\n",
              "      <td>I tried this stuff and it made my hair feel oi...</td>\n",
              "      <td>2005-02-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087969</th>\n",
              "      <td>US</td>\n",
              "      <td>38881154</td>\n",
              "      <td>R29TN19DCVI44R</td>\n",
              "      <td>B000052YHS</td>\n",
              "      <td>397259610</td>\n",
              "      <td>Gillette Mach3 Men's Razor, Mens Razors / Blades</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Good but...</td>\n",
              "      <td>This is an extremely good razor.  It definitel...</td>\n",
              "      <td>2005-02-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087970</th>\n",
              "      <td>US</td>\n",
              "      <td>14626862</td>\n",
              "      <td>R2X1AWYK6MGBE</td>\n",
              "      <td>B0002I3ZNO</td>\n",
              "      <td>833332489</td>\n",
              "      <td>V'Tae Oatmeal Silk Bath, Healing Therapy, 6-Ou...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>soothing</td>\n",
              "      <td>I bought this because I have extremely dry sen...</td>\n",
              "      <td>2005-02-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087971</th>\n",
              "      <td>US</td>\n",
              "      <td>35142523</td>\n",
              "      <td>R1L6C2F1ZB6YKT</td>\n",
              "      <td>B000063XHQ</td>\n",
              "      <td>442263387</td>\n",
              "      <td>Panasonic ER411NC Nose and Ear Hair Groomer</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>embarrassing gift, but great</td>\n",
              "      <td>Buy it for yourself. It's less than $15, and *...</td>\n",
              "      <td>2005-02-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087972</th>\n",
              "      <td>US</td>\n",
              "      <td>43699244</td>\n",
              "      <td>R1NH7XPY9N2EIS</td>\n",
              "      <td>B0001HYJW2</td>\n",
              "      <td>625583359</td>\n",
              "      <td>Philips Norelco T970 Accu-Vac Beard and Mousta...</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>Unfortunate</td>\n",
              "      <td>I've been using the Norelco series for about 5...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5087973 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-babe7f30-12a6-40a0-bfac-e3688181145c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-babe7f30-12a6-40a0-bfac-e3688181145c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-babe7f30-12a6-40a0-bfac-e3688181145c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# input_f = \"gdrive/MyDrive/Colab Notebooks/amazon_reviews_us_Beauty_v1_00.tsv\"\n",
        "input_f = \"amazon_reviews_us_Beauty_v1_00.tsv\"\n",
        "df = pd.read_csv(input_f,sep='\\t', error_bad_lines=False, warn_bad_lines=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1099d17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f1099d17",
        "outputId": "9672b34b-d929-4d5c-f2dc-1c44b3e71945"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        star_rating                                        review_body\n",
              "0                 5                   Love this, excellent sun block!!\n",
              "1                 5  The great thing about this cream is that it do...\n",
              "2                 5  Great Product, I'm 65 years old and this is al...\n",
              "3                 5  I use them as shower caps & conditioning caps....\n",
              "4                 5  This is my go-to daily sunblock. It leaves no ...\n",
              "...             ...                                                ...\n",
              "5087968           1  I tried this stuff and it made my hair feel oi...\n",
              "5087969           4  This is an extremely good razor.  It definitel...\n",
              "5087970           5  I bought this because I have extremely dry sen...\n",
              "5087971           5  Buy it for yourself. It's less than $15, and *...\n",
              "5087972           2  I've been using the Norelco series for about 5...\n",
              "\n",
              "[5087973 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bf9abfe-c5c0-4ab4-9a2d-88a048b33428\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Love this, excellent sun block!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>The great thing about this cream is that it do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087968</th>\n",
              "      <td>1</td>\n",
              "      <td>I tried this stuff and it made my hair feel oi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087969</th>\n",
              "      <td>4</td>\n",
              "      <td>This is an extremely good razor.  It definitel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087970</th>\n",
              "      <td>5</td>\n",
              "      <td>I bought this because I have extremely dry sen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087971</th>\n",
              "      <td>5</td>\n",
              "      <td>Buy it for yourself. It's less than $15, and *...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5087972</th>\n",
              "      <td>2</td>\n",
              "      <td>I've been using the Norelco series for about 5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5087973 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bf9abfe-c5c0-4ab4-9a2d-88a048b33428')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bf9abfe-c5c0-4ab4-9a2d-88a048b33428 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bf9abfe-c5c0-4ab4-9a2d-88a048b33428');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "## keep the reviews and rating fields in the input data frame\n",
        "reviews = df[['star_rating', 'review_body']]\n",
        "reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6bf9aac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "a6bf9aac",
        "outputId": "5f568570-0a85-4553-d811-06c5887932a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      star_rating                                        review_body\n",
              "0               1  The product was going to be a gift for my wife...\n",
              "1               1  Most of the eyelashes werent good to work with...\n",
              "2               1  I own a Jessy wig and love it, so I thought I ...\n",
              "3               1  Was not good for my hair did not work the way ...\n",
              "4               1  Don't get this it is not worth the money I got...\n",
              "...           ...                                                ...\n",
              "59995           5  Great product, makes hair cutting a breeze and...\n",
              "59996           5  With age comes with sagging in my face. This m...\n",
              "59997           5  I love the glass bottle and the scent. Those w...\n",
              "59998           5  Bought it for my 12 year-old daughter loved th...\n",
              "59999           5                                               good\n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c1dba45-5331-4c14-92c8-59224e78e6f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The product was going to be a gift for my wife...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Most of the eyelashes werent good to work with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I own a Jessy wig and love it, so I thought I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Was not good for my hair did not work the way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't get this it is not worth the money I got...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>5</td>\n",
              "      <td>Great product, makes hair cutting a breeze and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>5</td>\n",
              "      <td>With age comes with sagging in my face. This m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>5</td>\n",
              "      <td>I love the glass bottle and the scent. Those w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>5</td>\n",
              "      <td>Bought it for my 12 year-old daughter loved th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c1dba45-5331-4c14-92c8-59224e78e6f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c1dba45-5331-4c14-92c8-59224e78e6f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c1dba45-5331-4c14-92c8-59224e78e6f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "## balance dataset with 60k reviews\n",
        "## finding class 1\n",
        "class_1_reviews = reviews.loc[(reviews['star_rating'] == 1) | (reviews['star_rating'] == 2)].reset_index(drop = True)\n",
        "class_1_reviews = class_1_reviews.dropna()\n",
        "## finding class 2\n",
        "class_2_reviews = reviews.loc[reviews['star_rating'] == 3].reset_index(drop = True)\n",
        "class_2_reviews = class_2_reviews.dropna()\n",
        "## finding class 3\n",
        "class_3_reviews = reviews.loc[(reviews['star_rating'] == 4) | (reviews['star_rating'] == 5)].reset_index(drop = True)\n",
        "class_3_reviews = class_3_reviews.dropna()\n",
        "\n",
        "## randomly select 20,000 for each class \n",
        "n = 20000\n",
        "class_1_select = class_1_reviews.groupby('star_rating', group_keys=False).apply(lambda x: x.sample(10000, random_state = 42))\n",
        "class_2_select = class_2_reviews.sample(n, replace = False, random_state = 42)\n",
        "class_3_select = class_3_reviews.groupby('star_rating', group_keys=False).apply(lambda x: x.sample(10000, random_state = 42))\n",
        "\n",
        "df_all = pd.concat([class_1_select, class_2_select, class_3_select]).reset_index(drop=True)\n",
        "df_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67b2eef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67b2eef",
        "outputId": "9e3cd62d-af3b-4b19-c87e-d154110eca37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5.0], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df_all['star_rating'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2520f08c",
      "metadata": {
        "id": "2520f08c"
      },
      "outputs": [],
      "source": [
        "## Preprocessing\n",
        "rev = df_all['review_body']\n",
        "\n",
        "## convert all reviews into lowercase   \n",
        "text_lowercase = rev.str.lower()\n",
        "\n",
        "## remove the HTML and URLs from the reviews\n",
        "text_notag = []\n",
        "for item in text_lowercase:\n",
        "    soup = BeautifulSoup(item, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    text_notag.append(text)\n",
        "    \n",
        "## remove non-alphabetical characters\n",
        "text_cha = []\n",
        "for item in text_notag:\n",
        "    text = re.sub(r\"[^a-zA-Z |']\", ' ', item)\n",
        "    text_cha.append(text)\n",
        "    \n",
        "## remove extra spaces\n",
        "text_sp = []\n",
        "for item in text_cha:\n",
        "    text = re.sub(' +', ' ', item)\n",
        "    text_sp.append(text)\n",
        "        \n",
        "## perform contractions \n",
        "text_con = []\n",
        "for item in text_sp:\n",
        "    text = contractions.fix(item)\n",
        "    text_con.append(text)\n",
        "       \n",
        "# ## remove stopwords\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# text_stop = []\n",
        "# for item in text_con:\n",
        "#     item_split = item.split()\n",
        "#     i = ' '.join([word for word in item_split if word not in stop_words])\n",
        "#     text_stop.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb02491",
      "metadata": {
        "id": "beb02491"
      },
      "outputs": [],
      "source": [
        "df_all['new'] = text_sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3cf5be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2a3cf5be",
        "outputId": "ed6922cf-fa57-401f-d962-51be1b943921"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      star_rating                                        review_body  \\\n",
              "0               1  The product was going to be a gift for my wife...   \n",
              "1               1  Most of the eyelashes werent good to work with...   \n",
              "2               1  I own a Jessy wig and love it, so I thought I ...   \n",
              "3               1  Was not good for my hair did not work the way ...   \n",
              "4               1  Don't get this it is not worth the money I got...   \n",
              "...           ...                                                ...   \n",
              "59995           5  Great product, makes hair cutting a breeze and...   \n",
              "59996           5  With age comes with sagging in my face. This m...   \n",
              "59997           5  I love the glass bottle and the scent. Those w...   \n",
              "59998           5  Bought it for my 12 year-old daughter loved th...   \n",
              "59999           5                                               good   \n",
              "\n",
              "                                                     new  \n",
              "0      the product was going to be a gift for my wife...  \n",
              "1      most of the eyelashes werent good to work with...  \n",
              "2      i own a jessy wig and love it so i thought i w...  \n",
              "3      was not good for my hair did not work the way ...  \n",
              "4      don't get this it is not worth the money i got...  \n",
              "...                                                  ...  \n",
              "59995  great product makes hair cutting a breeze and ...  \n",
              "59996  with age comes with sagging in my face this mo...  \n",
              "59997  i love the glass bottle and the scent those wh...  \n",
              "59998  bought it for my year old daughter loved the c...  \n",
              "59999                                               good  \n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a27cdd44-15a5-4665-b81e-dfbebc9130f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The product was going to be a gift for my wife...</td>\n",
              "      <td>the product was going to be a gift for my wife...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Most of the eyelashes werent good to work with...</td>\n",
              "      <td>most of the eyelashes werent good to work with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I own a Jessy wig and love it, so I thought I ...</td>\n",
              "      <td>i own a jessy wig and love it so i thought i w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Was not good for my hair did not work the way ...</td>\n",
              "      <td>was not good for my hair did not work the way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't get this it is not worth the money I got...</td>\n",
              "      <td>don't get this it is not worth the money i got...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>5</td>\n",
              "      <td>Great product, makes hair cutting a breeze and...</td>\n",
              "      <td>great product makes hair cutting a breeze and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>5</td>\n",
              "      <td>With age comes with sagging in my face. This m...</td>\n",
              "      <td>with age comes with sagging in my face this mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>5</td>\n",
              "      <td>I love the glass bottle and the scent. Those w...</td>\n",
              "      <td>i love the glass bottle and the scent those wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>5</td>\n",
              "      <td>Bought it for my 12 year-old daughter loved th...</td>\n",
              "      <td>bought it for my year old daughter loved the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a27cdd44-15a5-4665-b81e-dfbebc9130f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a27cdd44-15a5-4665-b81e-dfbebc9130f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a27cdd44-15a5-4665-b81e-dfbebc9130f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8488fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5e8488fd",
        "outputId": "0d32282f-27b6-4c50-b3bd-c1e606311ed8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      star_rating                                        review_body  \\\n",
              "0               1  The product was going to be a gift for my wife...   \n",
              "1               1  Most of the eyelashes werent good to work with...   \n",
              "2               1  I own a Jessy wig and love it, so I thought I ...   \n",
              "3               1  Was not good for my hair did not work the way ...   \n",
              "4               1  Don't get this it is not worth the money I got...   \n",
              "...           ...                                                ...   \n",
              "59995           5  Great product, makes hair cutting a breeze and...   \n",
              "59996           5  With age comes with sagging in my face. This m...   \n",
              "59997           5  I love the glass bottle and the scent. Those w...   \n",
              "59998           5  Bought it for my 12 year-old daughter loved th...   \n",
              "59999           5                                               good   \n",
              "\n",
              "                                                     new  class  \n",
              "0      the product was going to be a gift for my wife...      1  \n",
              "1      most of the eyelashes werent good to work with...      1  \n",
              "2      i own a jessy wig and love it so i thought i w...      1  \n",
              "3      was not good for my hair did not work the way ...      1  \n",
              "4      don't get this it is not worth the money i got...      1  \n",
              "...                                                  ...    ...  \n",
              "59995  great product makes hair cutting a breeze and ...      3  \n",
              "59996  with age comes with sagging in my face this mo...      3  \n",
              "59997  i love the glass bottle and the scent those wh...      3  \n",
              "59998  bought it for my year old daughter loved the c...      3  \n",
              "59999                                               good      3  \n",
              "\n",
              "[60000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa525205-57ae-4073-9e61-092e0ff6307c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "      <th>new</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The product was going to be a gift for my wife...</td>\n",
              "      <td>the product was going to be a gift for my wife...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Most of the eyelashes werent good to work with...</td>\n",
              "      <td>most of the eyelashes werent good to work with...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I own a Jessy wig and love it, so I thought I ...</td>\n",
              "      <td>i own a jessy wig and love it so i thought i w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Was not good for my hair did not work the way ...</td>\n",
              "      <td>was not good for my hair did not work the way ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't get this it is not worth the money I got...</td>\n",
              "      <td>don't get this it is not worth the money i got...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>5</td>\n",
              "      <td>Great product, makes hair cutting a breeze and...</td>\n",
              "      <td>great product makes hair cutting a breeze and ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>5</td>\n",
              "      <td>With age comes with sagging in my face. This m...</td>\n",
              "      <td>with age comes with sagging in my face this mo...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>5</td>\n",
              "      <td>I love the glass bottle and the scent. Those w...</td>\n",
              "      <td>i love the glass bottle and the scent those wh...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>5</td>\n",
              "      <td>Bought it for my 12 year-old daughter loved th...</td>\n",
              "      <td>bought it for my year old daughter loved the c...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa525205-57ae-4073-9e61-092e0ff6307c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa525205-57ae-4073-9e61-092e0ff6307c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa525205-57ae-4073-9e61-092e0ff6307c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "class_spe = df_all['star_rating'].astype('int')\n",
        "for i in range (len(class_spe)):\n",
        "    if class_spe[i] == 1 or class_spe[i] == 2:\n",
        "        class_spe[i] = 1\n",
        "    if class_spe[i] == 3:\n",
        "        class_spe[i] = 2\n",
        "    if class_spe[i] == 4 or class_spe[i] == 5:\n",
        "        class_spe[i] = 3\n",
        "df_all['class'] = class_spe\n",
        "df_all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a374d193",
      "metadata": {
        "id": "a374d193"
      },
      "source": [
        "## 2. Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "905abebc",
      "metadata": {
        "id": "905abebc"
      },
      "source": [
        "### (a) Load the pretrained “word2vec-google-news-300”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b272f883",
      "metadata": {
        "id": "b272f883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ebab39-5d53-47c3-dd62-67e98c9fc197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "wv = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53717398",
      "metadata": {
        "id": "53717398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5774c145-a16d-4197-f127-df14bd20b89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check semantic similarity(part a)\n",
            "King - Man + woman = queen :  [('Queen', 0.4929388165473938)]\n",
            "excellent ~ outstanding :  0.55674857\n",
            "bad ~ terrible :  0.68286115\n"
          ]
        }
      ],
      "source": [
        "## check semantic simiarity \n",
        "\n",
        "##King -Man + woman = queen\n",
        "a = wv.most_similar(positive=['King', 'Woman'], negative=['Man'], topn = 1)\n",
        "\n",
        "## excellent ~ outstanding \n",
        "b = wv.similarity('excellent', 'outstanding')\n",
        "\n",
        "## bad ~ terrible\n",
        "c = wv.similarity('bad', 'terrible')\n",
        "\n",
        "print('check semantic similarity(part a)')\n",
        "print('King - Man + woman = queen : ', a)\n",
        "print('excellent ~ outstanding : ', b)\n",
        "print('bad ~ terrible : ', c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "646b6fc0",
      "metadata": {
        "id": "646b6fc0"
      },
      "source": [
        "### (b) Train a Word2Vec model using your own dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe672f3",
      "metadata": {
        "id": "7fe672f3",
        "outputId": "3ffd3dc8-7c71-4225-a2a3-1c4a17d73003"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "      <th>new</th>\n",
              "      <th>class</th>\n",
              "      <th>vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The product was going to be a gift for my wife...</td>\n",
              "      <td>the product was going to be a gift for my wife...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.00430329, -0.010766511, 0.01682123, 0.0084...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Most of the eyelashes werent good to work with...</td>\n",
              "      <td>most of the eyelashes were not good to work wi...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.005953749, -0.00430329, 0.007137782, -0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I own a Jessy wig and love it, so I thought I ...</td>\n",
              "      <td>i own a jessy wig and love it so i thought i w...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.008428434, -0.001132857, -0.0017439779, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Was not good for my hair did not work the way ...</td>\n",
              "      <td>was not good for my hair did not work the way ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.01682123, -0.0016720962, -0.0027225495, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't get this it is not worth the money I got...</td>\n",
              "      <td>do not get this it is not worth the money i go...</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0052448274, -0.016125174, 0.003165385, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>5</td>\n",
              "      <td>Great product, makes hair cutting a breeze and...</td>\n",
              "      <td>great product makes hair cutting a breeze and ...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.00023369631, -0.010766511, 0.004071655, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>5</td>\n",
              "      <td>With age comes with sagging in my face. This m...</td>\n",
              "      <td>with age comes with sagging in my face this mo...</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.0029325103, -0.015900223, 0.005987854, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>5</td>\n",
              "      <td>I love the glass bottle and the scent. Those w...</td>\n",
              "      <td>i love the glass bottle and the scent those wh...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.008428434, -0.0006823349, -0.00430329, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>5</td>\n",
              "      <td>Bought it for my 12 year-old daughter loved th...</td>\n",
              "      <td>bought it for my year old daughter loved the c...</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.015568742, -0.0042676544, 0.0019294819, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>5</td>\n",
              "      <td>good</td>\n",
              "      <td>good</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.0027225495]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      star_rating                                        review_body  \\\n",
              "0               1  The product was going to be a gift for my wife...   \n",
              "1               1  Most of the eyelashes werent good to work with...   \n",
              "2               1  I own a Jessy wig and love it, so I thought I ...   \n",
              "3               1  Was not good for my hair did not work the way ...   \n",
              "4               1  Don't get this it is not worth the money I got...   \n",
              "...           ...                                                ...   \n",
              "59995           5  Great product, makes hair cutting a breeze and...   \n",
              "59996           5  With age comes with sagging in my face. This m...   \n",
              "59997           5  I love the glass bottle and the scent. Those w...   \n",
              "59998           5  Bought it for my 12 year-old daughter loved th...   \n",
              "59999           5                                               good   \n",
              "\n",
              "                                                     new  class  \\\n",
              "0      the product was going to be a gift for my wife...      1   \n",
              "1      most of the eyelashes were not good to work wi...      1   \n",
              "2      i own a jessy wig and love it so i thought i w...      1   \n",
              "3      was not good for my hair did not work the way ...      1   \n",
              "4      do not get this it is not worth the money i go...      1   \n",
              "...                                                  ...    ...   \n",
              "59995  great product makes hair cutting a breeze and ...      3   \n",
              "59996  with age comes with sagging in my face this mo...      3   \n",
              "59997  i love the glass bottle and the scent those wh...      3   \n",
              "59998  bought it for my year old daughter loved the c...      3   \n",
              "59999                                               good      3   \n",
              "\n",
              "                                                     vec  \n",
              "0      [-0.00430329, -0.010766511, 0.01682123, 0.0084...  \n",
              "1      [-0.005953749, -0.00430329, 0.007137782, -0.00...  \n",
              "2      [-0.008428434, -0.001132857, -0.0017439779, -0...  \n",
              "3      [0.01682123, -0.0016720962, -0.0027225495, 0.0...  \n",
              "4      [-0.0052448274, -0.016125174, 0.003165385, 0.0...  \n",
              "...                                                  ...  \n",
              "59995  [-0.00023369631, -0.010766511, 0.004071655, 0....  \n",
              "59996  [0.0029325103, -0.015900223, 0.005987854, 0.00...  \n",
              "59997  [-0.008428434, -0.0006823349, -0.00430329, -0....  \n",
              "59998  [0.015568742, -0.0042676544, 0.0019294819, -0....  \n",
              "59999                                    [-0.0027225495]  \n",
              "\n",
              "[60000 rows x 5 columns]"
            ]
          },
          "execution_count": 311,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95beae0b",
      "metadata": {
        "id": "95beae0b"
      },
      "outputs": [],
      "source": [
        "sentences = [word_tokenize(x) for x in df_all['review_body']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b922b6",
      "metadata": {
        "id": "b0b922b6"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences=sentences, vector_size = 300, window = 13, min_count = 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84c70250",
      "metadata": {
        "id": "84c70250",
        "outputId": "c08806de-ed76-45bf-8540-046cadeead7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "check semantic similarity(part b)\n",
            "King - Man + woman = queen :  not included in the vocabulary\n",
            "excellent ~ outstanding :  0.62379426\n",
            "bad ~ terrible :  0.61245257\n"
          ]
        }
      ],
      "source": [
        "## check semantic simiarity \n",
        "\n",
        "##King -Man + woman = queen\n",
        "# a = model.wv.most_similar(positive=['King', 'Woman'], negative=['Man'], topn = 1)\n",
        "\n",
        "## excellent ~ outstanding \n",
        "b = model.wv.similarity('excellent', 'outstanding')\n",
        "\n",
        "## bad ~ terrible\n",
        "c = model.wv.similarity('bad', 'terrible')\n",
        "\n",
        "\n",
        "## vector('Paris') - vector('France') + vector('Italy') results in a vector that is very close to vector('Rome')\n",
        "\n",
        "print('check semantic similarity(part b)')\n",
        "print('King - Man + woman = queen : ', 'not included in the vocabulary')\n",
        "print('excellent ~ outstanding : ', b)\n",
        "print('bad ~ terrible : ', c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8180b5",
      "metadata": {
        "id": "2e8180b5"
      },
      "source": [
        "Ans: After comparing vectors generated by yourself and the pretrained model, I think that the pretrained word2vec model is better because it has more vocabularies and have more accurate semantic similarities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57eb2197",
      "metadata": {
        "id": "57eb2197"
      },
      "source": [
        "## 3. Simple models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_all['new']\n",
        "y = df_all['class'].astype('int')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "I-O4Iqfe7-qr"
      },
      "id": "I-O4Iqfe7-qr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ae4884",
      "metadata": {
        "id": "38ae4884"
      },
      "outputs": [],
      "source": [
        "def w2v(text):\n",
        "    text = text.split(\" \")\n",
        "    t = np.zeros(300)\n",
        "    n = len(text)\n",
        "    for i in text:\n",
        "        if i in wv:\n",
        "            t += wv[i]\n",
        "    return t/n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46ef6d5",
      "metadata": {
        "id": "e46ef6d5"
      },
      "outputs": [],
      "source": [
        "X_train_w2v = np.array([w2v(text) for text in X_train])\n",
        "X_test_w2v = np.array([w2v(text) for text in X_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55414111",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55414111",
        "outputId": "7ef8c855-dfe1-49c7-81c9-893fad8cd845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron()"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "clf = Perceptron()\n",
        "clf.fit(X_train_w2v, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035b7947",
      "metadata": {
        "id": "035b7947"
      },
      "outputs": [],
      "source": [
        "y_predict = clf.predict(X_test_w2v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e3421b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2e3421b",
        "outputId": "8d388b4b-080e-4b70-f64c-d623e136711e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5594166666666667"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "accuracy_score(y_test, y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using tfidf for comparision\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "X = np.array(df_all['new'])\n",
        "Y = np.array(df_all['star_rating'].astype('int'))\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
        "X= vectorizer.fit_transform(X)\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, Y, test_size=0.2)"
      ],
      "metadata": {
        "id": "u5gW-qpASaDt"
      },
      "id": "u5gW-qpASaDt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_tfidf = Perceptron()\n",
        "clf_tfidf.fit(X_train_tfidf, y_train_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfjuTsH0SaJK",
        "outputId": "4c7d2cb4-dbbf-414d-860f-db3dbcd55ce1"
      },
      "id": "mfjuTsH0SaJK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron()"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
        "accuracy_score(y_test_tfidf, y_predict_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Uxmk0SSaLw",
        "outputId": "be310b50-f4f0-4205-b746-a34f773fcc67"
      },
      "id": "a8Uxmk0SSaLw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5008333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPehwvIzSaUL"
      },
      "id": "mPehwvIzSaUL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cd94b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62cd94b8",
        "outputId": "892be15b-bdd9-493c-cb0c-f5c9ac577332"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "### SVM\n",
        "Linear_SVC = LinearSVC()\n",
        "Linear_SVC.fit(X_train_w2v, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b1cf709",
      "metadata": {
        "id": "0b1cf709"
      },
      "outputs": [],
      "source": [
        "y_predict_SVC = Linear_SVC.predict(X_test_w2v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bccb87c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bccb87c2",
        "outputId": "99e5b8da-ea9a-4795-8667-fa7b360559ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6119166666666667"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "accuracy_score(y_test, y_predict_SVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a86ed3",
      "metadata": {
        "id": "55a86ed3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tfidf comparision\n",
        "Linear_SVC_tfidf = LinearSVC()\n",
        "Linear_SVC_tfidf.fit(X_train_tfidf, y_train_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huK62y5LS9si",
        "outputId": "03b199c7-eb65-49bf-c4a1-488ad2947f16"
      },
      "id": "huK62y5LS9si",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_SVC_tfidf = Linear_SVC_tfidf.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "dFDGpXI2TDMA"
      },
      "id": "dFDGpXI2TDMA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy values with features Word2Vec for Perceptron is ', accuracy_score(y_test, y_predict))\n",
        "print('Accuracy values with features TF-IDF for Perceptron is ', accuracy_score(y_test_tfidf, y_predict_tfidf))\n",
        "print('Accuracy values with features Word2Vec for SVC is ', accuracy_score(y_test, y_predict_SVC))\n",
        "print('Accuracy values with features TF-IDF for SVC is ', accuracy_score(y_test_tfidf, y_predict_SVC_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HzeIlpxTXpG",
        "outputId": "24013a6d-09ea-405b-a033-1a4acdeb3e6b"
      },
      "id": "4HzeIlpxTXpG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy values with features Word2Vec for Perceptron is  0.5594166666666667\n",
            "Accuracy values with features TF-IDF for Perceptron is  0.5008333333333334\n",
            "Accuracy values with features Word2Vec for Perceptron is  0.6125\n",
            "Accuracy values with features TF-IDF for Perceptron is  0.5434166666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: Comparing the accuracy values, I found out that word2vec features has better performance on models compare to TF-IDF features with same preprocessing. SVM models have better performance than perceptron models for both types of features."
      ],
      "metadata": {
        "id": "zK2DAouTT7Fx"
      },
      "id": "zK2DAouTT7Fx"
    },
    {
      "cell_type": "markdown",
      "id": "669b9939",
      "metadata": {
        "id": "669b9939"
      },
      "source": [
        "## 4. Feedforward Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c25f5e",
      "metadata": {
        "id": "67c25f5e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) use the average Word2Vec vectors similar to the “Simple models” section and train the neural network."
      ],
      "metadata": {
        "id": "OhJimPcSVt04"
      },
      "id": "OhJimPcSVt04"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "from keras import Input\n",
        "# Build the model.\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(X_train_w2v.shape[1],)))\n",
        "## Embedding(vocab_size, 300, input_length=X_train_w2v.shape[1])\n",
        "## Input(shape=(X_train_w2v.shape[1],))\n",
        "# model.add(Dense(128, input_dim=300, activation='relu'))\n",
        "## Dense(64, activation='relu', input_shape = X_train_w2v[0].shape)\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# model.add(Dropout(0.7))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        " \n",
        "# Display the model summary.\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CoAOvvvV2cO",
        "outputId": "ae92458d-e450-4905-fe59-9f29e4680caa"
      },
      "id": "8CoAOvvvV2cO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 300)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,143\n",
            "Trainable params: 31,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_onehot=to_categorical(y_train -1)\n",
        "y_test_onehot=to_categorical(y_test - 1)"
      ],
      "metadata": {
        "id": "e01gYFTJ_RZ2"
      },
      "id": "e01gYFTJ_RZ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "training_results = model.fit(X_train_w2v, \n",
        "                             y_train_onehot, \n",
        "                             epochs=50, \n",
        "                             batch_size=50, \n",
        "                             validation_data=(X_test_w2v, y_test_onehot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt00FHIoWucJ",
        "outputId": "4da737af-b45a-4834-b150-887ff1768055"
      },
      "id": "Kt00FHIoWucJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "960/960 [==============================] - 9s 3ms/step - loss: 0.9408 - accuracy: 0.5399 - val_loss: 0.8645 - val_accuracy: 0.5928\n",
            "Epoch 2/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8859 - accuracy: 0.5891 - val_loss: 0.8566 - val_accuracy: 0.6037\n",
            "Epoch 3/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8741 - accuracy: 0.5949 - val_loss: 0.8366 - val_accuracy: 0.6160\n",
            "Epoch 4/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8635 - accuracy: 0.5979 - val_loss: 0.8410 - val_accuracy: 0.6115\n",
            "Epoch 5/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8548 - accuracy: 0.6043 - val_loss: 0.8283 - val_accuracy: 0.6193\n",
            "Epoch 6/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8473 - accuracy: 0.6064 - val_loss: 0.8273 - val_accuracy: 0.6210\n",
            "Epoch 7/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8395 - accuracy: 0.6105 - val_loss: 0.8208 - val_accuracy: 0.6283\n",
            "Epoch 8/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8361 - accuracy: 0.6137 - val_loss: 0.8169 - val_accuracy: 0.6294\n",
            "Epoch 9/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8301 - accuracy: 0.6144 - val_loss: 0.8389 - val_accuracy: 0.6104\n",
            "Epoch 10/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8277 - accuracy: 0.6187 - val_loss: 0.8138 - val_accuracy: 0.6297\n",
            "Epoch 11/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8200 - accuracy: 0.6205 - val_loss: 0.8145 - val_accuracy: 0.6299\n",
            "Epoch 12/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8152 - accuracy: 0.6236 - val_loss: 0.8085 - val_accuracy: 0.6352\n",
            "Epoch 13/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8132 - accuracy: 0.6261 - val_loss: 0.8099 - val_accuracy: 0.6308\n",
            "Epoch 14/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8059 - accuracy: 0.6267 - val_loss: 0.8079 - val_accuracy: 0.6324\n",
            "Epoch 15/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.8035 - accuracy: 0.6302 - val_loss: 0.8197 - val_accuracy: 0.6217\n",
            "Epoch 16/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7993 - accuracy: 0.6316 - val_loss: 0.8173 - val_accuracy: 0.6287\n",
            "Epoch 17/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7941 - accuracy: 0.6298 - val_loss: 0.8163 - val_accuracy: 0.6265\n",
            "Epoch 18/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7903 - accuracy: 0.6315 - val_loss: 0.8230 - val_accuracy: 0.6256\n",
            "Epoch 19/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7853 - accuracy: 0.6363 - val_loss: 0.8138 - val_accuracy: 0.6285\n",
            "Epoch 20/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7817 - accuracy: 0.6381 - val_loss: 0.8204 - val_accuracy: 0.6253\n",
            "Epoch 21/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7772 - accuracy: 0.6421 - val_loss: 0.8220 - val_accuracy: 0.6326\n",
            "Epoch 22/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7735 - accuracy: 0.6423 - val_loss: 0.8191 - val_accuracy: 0.6277\n",
            "Epoch 23/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7697 - accuracy: 0.6449 - val_loss: 0.8209 - val_accuracy: 0.6286\n",
            "Epoch 24/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7641 - accuracy: 0.6482 - val_loss: 0.8204 - val_accuracy: 0.6282\n",
            "Epoch 25/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7601 - accuracy: 0.6486 - val_loss: 0.8276 - val_accuracy: 0.6201\n",
            "Epoch 26/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7565 - accuracy: 0.6470 - val_loss: 0.8365 - val_accuracy: 0.6079\n",
            "Epoch 27/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7511 - accuracy: 0.6526 - val_loss: 0.8371 - val_accuracy: 0.6278\n",
            "Epoch 28/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7479 - accuracy: 0.6526 - val_loss: 0.8345 - val_accuracy: 0.6281\n",
            "Epoch 29/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7456 - accuracy: 0.6531 - val_loss: 0.8304 - val_accuracy: 0.6256\n",
            "Epoch 30/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7409 - accuracy: 0.6557 - val_loss: 0.8363 - val_accuracy: 0.6273\n",
            "Epoch 31/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7387 - accuracy: 0.6583 - val_loss: 0.8381 - val_accuracy: 0.6290\n",
            "Epoch 32/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7321 - accuracy: 0.6622 - val_loss: 0.8476 - val_accuracy: 0.6302\n",
            "Epoch 33/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7274 - accuracy: 0.6632 - val_loss: 0.8532 - val_accuracy: 0.6252\n",
            "Epoch 34/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7230 - accuracy: 0.6642 - val_loss: 0.8552 - val_accuracy: 0.6187\n",
            "Epoch 35/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7208 - accuracy: 0.6677 - val_loss: 0.8506 - val_accuracy: 0.6208\n",
            "Epoch 36/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7164 - accuracy: 0.6674 - val_loss: 0.8659 - val_accuracy: 0.6174\n",
            "Epoch 37/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7154 - accuracy: 0.6682 - val_loss: 0.9237 - val_accuracy: 0.6039\n",
            "Epoch 38/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7114 - accuracy: 0.6708 - val_loss: 0.8635 - val_accuracy: 0.6223\n",
            "Epoch 39/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7077 - accuracy: 0.6746 - val_loss: 0.8877 - val_accuracy: 0.6282\n",
            "Epoch 40/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7075 - accuracy: 0.6730 - val_loss: 0.8759 - val_accuracy: 0.6140\n",
            "Epoch 41/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7066 - accuracy: 0.6700 - val_loss: 0.9052 - val_accuracy: 0.6183\n",
            "Epoch 42/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.7003 - accuracy: 0.6766 - val_loss: 0.8906 - val_accuracy: 0.6247\n",
            "Epoch 43/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6956 - accuracy: 0.6764 - val_loss: 0.8888 - val_accuracy: 0.6201\n",
            "Epoch 44/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6962 - accuracy: 0.6753 - val_loss: 0.8896 - val_accuracy: 0.6179\n",
            "Epoch 45/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6915 - accuracy: 0.6804 - val_loss: 0.9035 - val_accuracy: 0.6154\n",
            "Epoch 46/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6897 - accuracy: 0.6799 - val_loss: 0.8935 - val_accuracy: 0.6073\n",
            "Epoch 47/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6834 - accuracy: 0.6840 - val_loss: 0.9236 - val_accuracy: 0.6202\n",
            "Epoch 48/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6813 - accuracy: 0.6851 - val_loss: 0.9266 - val_accuracy: 0.6210\n",
            "Epoch 49/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6804 - accuracy: 0.6850 - val_loss: 0.9096 - val_accuracy: 0.6202\n",
            "Epoch 50/50\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.6747 - accuracy: 0.6861 - val_loss: 0.9238 - val_accuracy: 0.6144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fnn = pd.DataFrame(training_results.history)\n",
        "df_fnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ruyZ9PZOE4ht",
        "outputId": "45c2cdbd-5641-402d-e19d-b58fdd538a0f"
      },
      "id": "ruyZ9PZOE4ht",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy\n",
              "0   0.940769  0.539896  0.864543      0.592750\n",
              "1   0.885943  0.589104  0.856613      0.603750\n",
              "2   0.874111  0.594917  0.836551      0.616000\n",
              "3   0.863508  0.597875  0.840972      0.611500\n",
              "4   0.854780  0.604333  0.828261      0.619333\n",
              "5   0.847319  0.606354  0.827261      0.621000\n",
              "6   0.839482  0.610521  0.820804      0.628333\n",
              "7   0.836070  0.613750  0.816854      0.629417\n",
              "8   0.830103  0.614438  0.838890      0.610417\n",
              "9   0.827678  0.618667  0.813789      0.629667\n",
              "10  0.819958  0.620458  0.814520      0.629917\n",
              "11  0.815179  0.623563  0.808464      0.635167\n",
              "12  0.813223  0.626125  0.809937      0.630833\n",
              "13  0.805874  0.626708  0.807856      0.632417\n",
              "14  0.803514  0.630208  0.819704      0.621750\n",
              "15  0.799269  0.631604  0.817321      0.628667\n",
              "16  0.794091  0.629812  0.816287      0.626500\n",
              "17  0.790295  0.631479  0.823041      0.625583\n",
              "18  0.785278  0.636312  0.813835      0.628500\n",
              "19  0.781724  0.638083  0.820400      0.625333\n",
              "20  0.777177  0.642083  0.821966      0.632583\n",
              "21  0.773489  0.642271  0.819105      0.627750\n",
              "22  0.769705  0.644917  0.820871      0.628583\n",
              "23  0.764091  0.648229  0.820419      0.628167\n",
              "24  0.760072  0.648625  0.827562      0.620083\n",
              "25  0.756488  0.647021  0.836476      0.607917\n",
              "26  0.751089  0.652604  0.837088      0.627833\n",
              "27  0.747885  0.652583  0.834547      0.628083\n",
              "28  0.745554  0.653125  0.830421      0.625583\n",
              "29  0.740886  0.655667  0.836333      0.627333\n",
              "30  0.738690  0.658292  0.838098      0.629000\n",
              "31  0.732135  0.662188  0.847585      0.630167\n",
              "32  0.727403  0.663188  0.853209      0.625167\n",
              "33  0.723034  0.664167  0.855238      0.618667\n",
              "34  0.720849  0.667667  0.850619      0.620833\n",
              "35  0.716393  0.667396  0.865868      0.617417\n",
              "36  0.715425  0.668187  0.923728      0.603917\n",
              "37  0.711396  0.670833  0.863524      0.622333\n",
              "38  0.707715  0.674563  0.887703      0.628167\n",
              "39  0.707458  0.673042  0.875877      0.614000\n",
              "40  0.706567  0.669979  0.905247      0.618333\n",
              "41  0.700253  0.676625  0.890587      0.624667\n",
              "42  0.695647  0.676396  0.888847      0.620083\n",
              "43  0.696174  0.675313  0.889593      0.617917\n",
              "44  0.691475  0.680354  0.903546      0.615417\n",
              "45  0.689664  0.679896  0.893479      0.607333\n",
              "46  0.683417  0.684000  0.923578      0.620250\n",
              "47  0.681290  0.685104  0.926577      0.621000\n",
              "48  0.680420  0.684958  0.909565      0.620167\n",
              "49  0.674666  0.686104  0.923761      0.614417"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81e23c76-b81e-44ba-8b22-09f21dbf3fe2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.940769</td>\n",
              "      <td>0.539896</td>\n",
              "      <td>0.864543</td>\n",
              "      <td>0.592750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.885943</td>\n",
              "      <td>0.589104</td>\n",
              "      <td>0.856613</td>\n",
              "      <td>0.603750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.874111</td>\n",
              "      <td>0.594917</td>\n",
              "      <td>0.836551</td>\n",
              "      <td>0.616000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.863508</td>\n",
              "      <td>0.597875</td>\n",
              "      <td>0.840972</td>\n",
              "      <td>0.611500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.854780</td>\n",
              "      <td>0.604333</td>\n",
              "      <td>0.828261</td>\n",
              "      <td>0.619333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.847319</td>\n",
              "      <td>0.606354</td>\n",
              "      <td>0.827261</td>\n",
              "      <td>0.621000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.839482</td>\n",
              "      <td>0.610521</td>\n",
              "      <td>0.820804</td>\n",
              "      <td>0.628333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.836070</td>\n",
              "      <td>0.613750</td>\n",
              "      <td>0.816854</td>\n",
              "      <td>0.629417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.830103</td>\n",
              "      <td>0.614438</td>\n",
              "      <td>0.838890</td>\n",
              "      <td>0.610417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.827678</td>\n",
              "      <td>0.618667</td>\n",
              "      <td>0.813789</td>\n",
              "      <td>0.629667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.819958</td>\n",
              "      <td>0.620458</td>\n",
              "      <td>0.814520</td>\n",
              "      <td>0.629917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.815179</td>\n",
              "      <td>0.623563</td>\n",
              "      <td>0.808464</td>\n",
              "      <td>0.635167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.813223</td>\n",
              "      <td>0.626125</td>\n",
              "      <td>0.809937</td>\n",
              "      <td>0.630833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.805874</td>\n",
              "      <td>0.626708</td>\n",
              "      <td>0.807856</td>\n",
              "      <td>0.632417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.803514</td>\n",
              "      <td>0.630208</td>\n",
              "      <td>0.819704</td>\n",
              "      <td>0.621750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.799269</td>\n",
              "      <td>0.631604</td>\n",
              "      <td>0.817321</td>\n",
              "      <td>0.628667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.794091</td>\n",
              "      <td>0.629812</td>\n",
              "      <td>0.816287</td>\n",
              "      <td>0.626500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.790295</td>\n",
              "      <td>0.631479</td>\n",
              "      <td>0.823041</td>\n",
              "      <td>0.625583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.785278</td>\n",
              "      <td>0.636312</td>\n",
              "      <td>0.813835</td>\n",
              "      <td>0.628500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.781724</td>\n",
              "      <td>0.638083</td>\n",
              "      <td>0.820400</td>\n",
              "      <td>0.625333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.777177</td>\n",
              "      <td>0.642083</td>\n",
              "      <td>0.821966</td>\n",
              "      <td>0.632583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.773489</td>\n",
              "      <td>0.642271</td>\n",
              "      <td>0.819105</td>\n",
              "      <td>0.627750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.769705</td>\n",
              "      <td>0.644917</td>\n",
              "      <td>0.820871</td>\n",
              "      <td>0.628583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.764091</td>\n",
              "      <td>0.648229</td>\n",
              "      <td>0.820419</td>\n",
              "      <td>0.628167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.760072</td>\n",
              "      <td>0.648625</td>\n",
              "      <td>0.827562</td>\n",
              "      <td>0.620083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.756488</td>\n",
              "      <td>0.647021</td>\n",
              "      <td>0.836476</td>\n",
              "      <td>0.607917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.751089</td>\n",
              "      <td>0.652604</td>\n",
              "      <td>0.837088</td>\n",
              "      <td>0.627833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.747885</td>\n",
              "      <td>0.652583</td>\n",
              "      <td>0.834547</td>\n",
              "      <td>0.628083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.745554</td>\n",
              "      <td>0.653125</td>\n",
              "      <td>0.830421</td>\n",
              "      <td>0.625583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.740886</td>\n",
              "      <td>0.655667</td>\n",
              "      <td>0.836333</td>\n",
              "      <td>0.627333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.738690</td>\n",
              "      <td>0.658292</td>\n",
              "      <td>0.838098</td>\n",
              "      <td>0.629000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.732135</td>\n",
              "      <td>0.662188</td>\n",
              "      <td>0.847585</td>\n",
              "      <td>0.630167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.727403</td>\n",
              "      <td>0.663188</td>\n",
              "      <td>0.853209</td>\n",
              "      <td>0.625167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.723034</td>\n",
              "      <td>0.664167</td>\n",
              "      <td>0.855238</td>\n",
              "      <td>0.618667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.720849</td>\n",
              "      <td>0.667667</td>\n",
              "      <td>0.850619</td>\n",
              "      <td>0.620833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.716393</td>\n",
              "      <td>0.667396</td>\n",
              "      <td>0.865868</td>\n",
              "      <td>0.617417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.715425</td>\n",
              "      <td>0.668187</td>\n",
              "      <td>0.923728</td>\n",
              "      <td>0.603917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.711396</td>\n",
              "      <td>0.670833</td>\n",
              "      <td>0.863524</td>\n",
              "      <td>0.622333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.707715</td>\n",
              "      <td>0.674563</td>\n",
              "      <td>0.887703</td>\n",
              "      <td>0.628167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.707458</td>\n",
              "      <td>0.673042</td>\n",
              "      <td>0.875877</td>\n",
              "      <td>0.614000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.706567</td>\n",
              "      <td>0.669979</td>\n",
              "      <td>0.905247</td>\n",
              "      <td>0.618333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.700253</td>\n",
              "      <td>0.676625</td>\n",
              "      <td>0.890587</td>\n",
              "      <td>0.624667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.695647</td>\n",
              "      <td>0.676396</td>\n",
              "      <td>0.888847</td>\n",
              "      <td>0.620083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.696174</td>\n",
              "      <td>0.675313</td>\n",
              "      <td>0.889593</td>\n",
              "      <td>0.617917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.691475</td>\n",
              "      <td>0.680354</td>\n",
              "      <td>0.903546</td>\n",
              "      <td>0.615417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.689664</td>\n",
              "      <td>0.679896</td>\n",
              "      <td>0.893479</td>\n",
              "      <td>0.607333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.683417</td>\n",
              "      <td>0.684000</td>\n",
              "      <td>0.923578</td>\n",
              "      <td>0.620250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.681290</td>\n",
              "      <td>0.685104</td>\n",
              "      <td>0.926577</td>\n",
              "      <td>0.621000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.680420</td>\n",
              "      <td>0.684958</td>\n",
              "      <td>0.909565</td>\n",
              "      <td>0.620167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.674666</td>\n",
              "      <td>0.686104</td>\n",
              "      <td>0.923761</td>\n",
              "      <td>0.614417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81e23c76-b81e-44ba-8b22-09f21dbf3fe2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81e23c76-b81e-44ba-8b22-09f21dbf3fe2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81e23c76-b81e-44ba-8b22-09f21dbf3fe2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=df_fnn['loss']\n",
        "val_loss=df_fnn['val_loss']\n",
        "epochs=range(len(loss)) # Get number of epochs\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "J-vtevi4FQu9",
        "outputId": "afdd043e-9459-47b0-87ea-2d6905539f4a"
      },
      "id": "J-vtevi4FQu9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc=df_fnn['accuracy']\n",
        "val_acc=df_fnn['val_accuracy']\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bBfyilVVGpf6",
        "outputId": "eb5f1d38-34b3-4948-b8a7-5cd7090bb182"
      },
      "id": "bBfyilVVGpf6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re = model.evaluate(X_test_w2v, y_test_onehot)\n",
        "print('Accuracy for 4a FNN is ' , re[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymG_crVYGpn9",
        "outputId": "bcff38b8-c800-440f-f544-054367455911"
      },
      "id": "ymG_crVYGpn9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 3ms/step - loss: 0.9238 - accuracy: 0.6144\n",
            "Accuracy for 4a FNN is  0.6144166588783264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4UTf1QdG0Jq"
      },
      "id": "a4UTf1QdG0Jq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "370daByyG0X6"
      },
      "id": "370daByyG0X6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) concatenate the first 10 Word2Vec vectors for each review as the input feature (x = [WT 1,...,WT 10]) and train the neural network."
      ],
      "metadata": {
        "id": "Ey9uaDDiMURP"
      },
      "id": "Ey9uaDDiMURP"
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_first10(text):\n",
        "    text = text.split(\" \")\n",
        "    v = np.zeros((300*10))\n",
        "    j = 0\n",
        "    for i in text:\n",
        "      if j == 10:\n",
        "        break\n",
        "      if i in wv:\n",
        "        v[j*300:(j+1)*300] = wv[i]\n",
        "        j += 1\n",
        "    return np.array(v)"
      ],
      "metadata": {
        "id": "Ud7uu5IcUvKp"
      },
      "id": "Ud7uu5IcUvKp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGVvhbN3jhPT"
      },
      "id": "mGVvhbN3jhPT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_first10('the product was going to be').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn30GHx6IbVq",
        "outputId": "c6e04cd8-9273-4c96-e485-a67ba97520fa"
      },
      "id": "Kn30GHx6IbVq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000,)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_w2v_first10 = np.array([w2v_first10(text) for text in X_train])\n",
        "X_test_w2v_first10 = np.array([w2v_first10(text) for text in X_test])"
      ],
      "metadata": {
        "id": "srKSOkYTUE4N"
      },
      "id": "srKSOkYTUE4N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_w2v_first10.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2miDa0XBYYJQ",
        "outputId": "636bf1c7-c55e-49ca-d728-d50a42de8199"
      },
      "id": "2miDa0XBYYJQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 3000)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Embedding, LSTM, Flatten, Dropout, Conv2D, MaxPooling2D\n",
        "from keras import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Build the model.\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(X_train_w2v_first10.shape[1],)))\n",
        "# model.add(Input(shape=(X_train_w2v.shape[1],)))\n",
        "## Embedding(vocab_size, 300, input_length=X_train_w2v.shape[1])\n",
        "## Input(shape=(X_train_w2v.shape[1],))\n",
        "# model.add(Dense(128, input_dim=300, activation='relu'))\n",
        "# model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.7))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "## Display the model summary.\n",
        "model.summary()\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss='categorical_crossentropy',\n",
        "              \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iZpFCrPYwtq",
        "outputId": "b94ad2b4-62be-41c5-c4ea-bfb3d7591e5f"
      },
      "id": "8iZpFCrPYwtq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               300100    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 301,143\n",
            "Trainable params: 301,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_results_5b = model.fit(X_train_w2v_first10, \n",
        "                             y_train_onehot, \n",
        "                             epochs=50, \n",
        "                             batch_size=64, \n",
        "                             callbacks = [callback],\n",
        "                             validation_data=(X_test_w2v_first10, y_test_onehot))"
      ],
      "metadata": {
        "id": "Z8K2rMKuZAeK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a3d72d-1ae1-4f3d-865c-4cbb2a710abf"
      },
      "id": "Z8K2rMKuZAeK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 5s 5ms/step - loss: 1.0360 - accuracy: 0.4390 - val_loss: 0.9780 - val_accuracy: 0.4938\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9958 - accuracy: 0.4815 - val_loss: 0.9672 - val_accuracy: 0.4978\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9788 - accuracy: 0.4983 - val_loss: 0.9547 - val_accuracy: 0.5135\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9696 - accuracy: 0.5027 - val_loss: 0.9487 - val_accuracy: 0.5148\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9593 - accuracy: 0.5131 - val_loss: 0.9484 - val_accuracy: 0.5155\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.9525 - accuracy: 0.5182 - val_loss: 0.9454 - val_accuracy: 0.5248\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9433 - accuracy: 0.5245 - val_loss: 0.9471 - val_accuracy: 0.5268\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9404 - accuracy: 0.5259 - val_loss: 0.9444 - val_accuracy: 0.5287\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9370 - accuracy: 0.5311 - val_loss: 0.9411 - val_accuracy: 0.5291\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9311 - accuracy: 0.5373 - val_loss: 0.9425 - val_accuracy: 0.5322\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.9258 - accuracy: 0.5392 - val_loss: 0.9625 - val_accuracy: 0.5246\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9180 - accuracy: 0.5425 - val_loss: 0.9410 - val_accuracy: 0.5326\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9137 - accuracy: 0.5481 - val_loss: 0.9416 - val_accuracy: 0.5293\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9081 - accuracy: 0.5532 - val_loss: 0.9683 - val_accuracy: 0.5321\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.9067 - accuracy: 0.5511 - val_loss: 0.9476 - val_accuracy: 0.5292\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.9002 - accuracy: 0.5576 - val_loss: 0.9557 - val_accuracy: 0.5329\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.8980 - accuracy: 0.5584 - val_loss: 0.9422 - val_accuracy: 0.5296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re2 = model.evaluate(X_test_w2v_first10, y_test_onehot)\n",
        "print('Accuracy for 4b FNN is ' , re2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDgBHg1cg6Gf",
        "outputId": "2c3c5b6e-fe4d-4b10-bcc2-911646994c55"
      },
      "id": "wDgBHg1cg6Gf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.9422 - accuracy: 0.5296\n",
            "Accuracy for 4b FNN is  0.5295833349227905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The model from 4a has better accuracy about 61%. The seconde is the model from simple model perceptron. 4b has the least accuracy model about 53%."
      ],
      "metadata": {
        "id": "oVZQnkd5tiGA"
      },
      "id": "oVZQnkd5tiGA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Recurrent Neural Networks"
      ],
      "metadata": {
        "id": "JSYkjeU278jo"
      },
      "id": "JSYkjeU278jo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (a) Train a simple RNN for sentiment analysis"
      ],
      "metadata": {
        "id": "1UH8cE1-8FZf"
      },
      "id": "1UH8cE1-8FZf"
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_first10(text):\n",
        "    text = text.split(\" \")\n",
        "    n = len(text)\n",
        "    d = []\n",
        "    j = 0\n",
        "    # t = np.zeros(300)\n",
        "    for i in text:\n",
        "        if j == 10:\n",
        "            break\n",
        "        if i in wv:\n",
        "            print(i)\n",
        "            j += 1\n",
        "            d.append(wv[i])\n",
        "    for k in range(j, 10):\n",
        "        d.append(np.zeros(300))\n",
        "    return np.array(d)"
      ],
      "metadata": {
        "id": "0uHqEDDB0nzr"
      },
      "id": "0uHqEDDB0nzr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUXwnQgvxSF9"
      },
      "id": "oUXwnQgvxSF9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_first20(text):\n",
        "    text = text.split(\" \")\n",
        "    d = []\n",
        "    j = 0\n",
        "    # t = np.zeros(300)\n",
        "    for i in text:\n",
        "        if j == 20:\n",
        "            break\n",
        "        if i in wv:\n",
        "            j += 1\n",
        "            d.append(wv[i])\n",
        "    for k in range(j, 20):\n",
        "        d.append(np.zeros(300))\n",
        "    return np.array(d)"
      ],
      "metadata": {
        "id": "AZlwwGscEAuC"
      },
      "id": "AZlwwGscEAuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_w2v_first20 = np.array([w2v_first20(text) for text in X_train])\n",
        "X_test_w2v_first20 = np.array([w2v_first20(text) for text in X_test])"
      ],
      "metadata": {
        "id": "z7Q7JSTwF9_U"
      },
      "id": "z7Q7JSTwF9_U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "X_train_w2v_first20 = np.asarray(X_train_w2v_first20).astype('float32')\n",
        "train_tensor = tf.convert_to_tensor(X_train_w2v_first20)\n",
        "\n",
        "X_test_w2v_first20 = np.asarray(X_test_w2v_first20).astype('float32')\n",
        "test_tensor = tf.convert_to_tensor(X_test_w2v_first20)"
      ],
      "metadata": {
        "id": "hLKnSV0K15xP"
      },
      "id": "hLKnSV0K15xP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tensor1 = np.asarray(y_train).astype('float32')\n",
        "y_tensor_train = tf.convert_to_tensor(y_tensor1)\n",
        "\n",
        "y_tensor2 = np.asarray(y_test).astype('float32')\n",
        "y_tensor_test = tf.convert_to_tensor(y_tensor2)"
      ],
      "metadata": {
        "id": "UHIKEvHTTRr3"
      },
      "id": "UHIKEvHTTRr3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXe8LDsX7rdx",
        "outputId": "12243049-1b51-4a56-e02d-6876e5121bce"
      },
      "id": "nXe8LDsX7rdx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12000, 20, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXKy-qojJPl_"
      },
      "id": "RXKy-qojJPl_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(train_tensor.shape[1],train_tensor.shape[2])))\n",
        "# model.add(Flatten())\n",
        "# model.add(Embedding(train_tensor.shape[0], 300, input_length = 20))\n",
        "model.add(SimpleRNN(20, return_sequences=True))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.add(Dropout(0.4))\n",
        "# model.build(input_shape=X_train_w2v_first20.shape)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0huUX-HrYst",
        "outputId": "088ea148-d0a6-4d8d-8605-ab080976b96a"
      },
      "id": "u0huUX-HrYst",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 20, 20)            6420      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 1203      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,623\n",
            "Trainable params: 7,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_results_5a = model.fit(train_tensor, \n",
        "                             y_train_onehot, \n",
        "                             epochs=50, \n",
        "                             batch_size=50, \n",
        "                            \n",
        "                             validation_data=(test_tensor, y_test_onehot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY7-Qjfh9OzY",
        "outputId": "4fa7b2ad-254e-4582-a7c6-cbbd2816f1fe"
      },
      "id": "uY7-Qjfh9OzY",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "960/960 [==============================] - 11s 10ms/step - loss: nan - accuracy: 0.3718 - val_loss: 1.0014 - val_accuracy: 0.4832\n",
            "Epoch 2/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4157 - val_loss: 0.9689 - val_accuracy: 0.5064\n",
            "Epoch 3/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4266 - val_loss: 0.9518 - val_accuracy: 0.5221\n",
            "Epoch 4/50\n",
            "960/960 [==============================] - 10s 10ms/step - loss: nan - accuracy: 0.4289 - val_loss: 0.9459 - val_accuracy: 0.5319\n",
            "Epoch 5/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4320 - val_loss: 0.9327 - val_accuracy: 0.5421\n",
            "Epoch 6/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4411 - val_loss: 0.9265 - val_accuracy: 0.5502\n",
            "Epoch 7/50\n",
            "960/960 [==============================] - 10s 10ms/step - loss: nan - accuracy: 0.4417 - val_loss: 0.9222 - val_accuracy: 0.5538\n",
            "Epoch 8/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4448 - val_loss: 0.9171 - val_accuracy: 0.5607\n",
            "Epoch 9/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4466 - val_loss: 0.9122 - val_accuracy: 0.5639\n",
            "Epoch 10/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4471 - val_loss: 0.9087 - val_accuracy: 0.5643\n",
            "Epoch 11/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4451 - val_loss: 0.9080 - val_accuracy: 0.5694\n",
            "Epoch 12/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4485 - val_loss: 0.9048 - val_accuracy: 0.5683\n",
            "Epoch 13/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4528 - val_loss: 0.9019 - val_accuracy: 0.5717\n",
            "Epoch 14/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4482 - val_loss: 0.9007 - val_accuracy: 0.5719\n",
            "Epoch 15/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4511 - val_loss: 0.9025 - val_accuracy: 0.5698\n",
            "Epoch 16/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4522 - val_loss: 0.8985 - val_accuracy: 0.5723\n",
            "Epoch 17/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4510 - val_loss: 0.9008 - val_accuracy: 0.5708\n",
            "Epoch 18/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4544 - val_loss: 0.8976 - val_accuracy: 0.5708\n",
            "Epoch 19/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4565 - val_loss: 0.9051 - val_accuracy: 0.5683\n",
            "Epoch 20/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4530 - val_loss: 0.8961 - val_accuracy: 0.5717\n",
            "Epoch 21/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4537 - val_loss: 0.8947 - val_accuracy: 0.5736\n",
            "Epoch 22/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4560 - val_loss: 0.8937 - val_accuracy: 0.5739\n",
            "Epoch 23/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4580 - val_loss: 0.8941 - val_accuracy: 0.5767\n",
            "Epoch 24/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4579 - val_loss: 0.8906 - val_accuracy: 0.5778\n",
            "Epoch 25/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4571 - val_loss: 0.8958 - val_accuracy: 0.5744\n",
            "Epoch 26/50\n",
            "960/960 [==============================] - 10s 10ms/step - loss: nan - accuracy: 0.4549 - val_loss: 0.8896 - val_accuracy: 0.5784\n",
            "Epoch 27/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4578 - val_loss: 0.8949 - val_accuracy: 0.5698\n",
            "Epoch 28/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4565 - val_loss: 0.8907 - val_accuracy: 0.5782\n",
            "Epoch 29/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4570 - val_loss: 0.8883 - val_accuracy: 0.5765\n",
            "Epoch 30/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4573 - val_loss: 0.8931 - val_accuracy: 0.5777\n",
            "Epoch 31/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4562 - val_loss: 0.8916 - val_accuracy: 0.5783\n",
            "Epoch 32/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4559 - val_loss: 0.8890 - val_accuracy: 0.5798\n",
            "Epoch 33/50\n",
            "960/960 [==============================] - 10s 10ms/step - loss: nan - accuracy: 0.4582 - val_loss: 0.8869 - val_accuracy: 0.5802\n",
            "Epoch 34/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4588 - val_loss: 0.8881 - val_accuracy: 0.5788\n",
            "Epoch 35/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4599 - val_loss: 0.8860 - val_accuracy: 0.5803\n",
            "Epoch 36/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4611 - val_loss: 0.8870 - val_accuracy: 0.5778\n",
            "Epoch 37/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4587 - val_loss: 0.8856 - val_accuracy: 0.5803\n",
            "Epoch 38/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4562 - val_loss: 0.8870 - val_accuracy: 0.5758\n",
            "Epoch 39/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4582 - val_loss: 0.8877 - val_accuracy: 0.5752\n",
            "Epoch 40/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4602 - val_loss: 0.8858 - val_accuracy: 0.5783\n",
            "Epoch 41/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4602 - val_loss: 0.8856 - val_accuracy: 0.5778\n",
            "Epoch 42/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4626 - val_loss: 0.8916 - val_accuracy: 0.5763\n",
            "Epoch 43/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4615 - val_loss: 0.8833 - val_accuracy: 0.5822\n",
            "Epoch 44/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4601 - val_loss: 0.8848 - val_accuracy: 0.5800\n",
            "Epoch 45/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4604 - val_loss: 0.8843 - val_accuracy: 0.5835\n",
            "Epoch 46/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4617 - val_loss: 0.8846 - val_accuracy: 0.5817\n",
            "Epoch 47/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4640 - val_loss: 0.8838 - val_accuracy: 0.5846\n",
            "Epoch 48/50\n",
            "960/960 [==============================] - 9s 9ms/step - loss: nan - accuracy: 0.4641 - val_loss: 0.8882 - val_accuracy: 0.5747\n",
            "Epoch 49/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4631 - val_loss: 0.8828 - val_accuracy: 0.5805\n",
            "Epoch 50/50\n",
            "960/960 [==============================] - 9s 10ms/step - loss: nan - accuracy: 0.4674 - val_loss: 0.8859 - val_accuracy: 0.5811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re3 = model.evaluate(test_tensor, y_test_onehot)\n",
        "print('Accuracy for 5a simple RNN is ' , re3[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQA_FFxcGlRr",
        "outputId": "e42e8473-a8eb-477e-d07e-5a39c017875a"
      },
      "id": "rQA_FFxcGlRr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8859 - accuracy: 0.5811\n",
            "Accuracy for 5a simple RNN is  0.581083357334137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: I conclude that the RNN simple model have worse performance(about 58% accuracy) than the Feedforward neural network."
      ],
      "metadata": {
        "id": "RZCI4ZrZuJ7F"
      },
      "id": "RZCI4ZrZuJ7F"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qfYth9YguI7l"
      },
      "id": "qfYth9YguI7l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5b. GRU RNN"
      ],
      "metadata": {
        "id": "1KDXEiylcCF9"
      },
      "id": "1KDXEiylcCF9"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, SimpleRNN, Bidirectional, GRU\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(train_tensor.shape[1],train_tensor.shape[2])))\n",
        "# model.add(Flatten())\n",
        "# model.add(Embedding(train_tensor.shape[0], 300, input_length = 20))\n",
        "model.add(Bidirectional(GRU(20, return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.add(Dropout(0.4))\n",
        "# model.build(input_shape=X_train_w2v_first20.shape)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9-psfficFn8",
        "outputId": "aa81fa6e-17ca-4773-de14-42864701ab63"
      },
      "id": "U9-psfficFn8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 20, 40)           38640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 2403      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,043\n",
            "Trainable params: 41,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_results_5b = model.fit(train_tensor, \n",
        "                             y_train_onehot, \n",
        "                             epochs=75, \n",
        "                             batch_size=50, \n",
        "                            \n",
        "                             validation_data=(test_tensor, y_test_onehot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZVgokgjcJb1",
        "outputId": "53020678-3daf-46a5-ee46-493942cce5ef"
      },
      "id": "JZVgokgjcJb1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "960/960 [==============================] - 11s 7ms/step - loss: nan - accuracy: 0.3854 - val_loss: 1.0110 - val_accuracy: 0.4999\n",
            "Epoch 2/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4257 - val_loss: 0.9476 - val_accuracy: 0.5387\n",
            "Epoch 3/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4378 - val_loss: 0.9261 - val_accuracy: 0.5596\n",
            "Epoch 4/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4410 - val_loss: 0.9145 - val_accuracy: 0.5638\n",
            "Epoch 5/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4487 - val_loss: 0.9054 - val_accuracy: 0.5707\n",
            "Epoch 6/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4481 - val_loss: 0.9023 - val_accuracy: 0.5715\n",
            "Epoch 7/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4547 - val_loss: 0.8958 - val_accuracy: 0.5770\n",
            "Epoch 8/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4542 - val_loss: 0.8895 - val_accuracy: 0.5788\n",
            "Epoch 9/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4555 - val_loss: 0.8889 - val_accuracy: 0.5791\n",
            "Epoch 10/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4613 - val_loss: 0.8883 - val_accuracy: 0.5802\n",
            "Epoch 11/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4620 - val_loss: 0.8789 - val_accuracy: 0.5861\n",
            "Epoch 12/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4604 - val_loss: 0.8768 - val_accuracy: 0.5891\n",
            "Epoch 13/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4622 - val_loss: 0.8768 - val_accuracy: 0.5887\n",
            "Epoch 14/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4660 - val_loss: 0.8733 - val_accuracy: 0.5915\n",
            "Epoch 15/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4638 - val_loss: 0.8673 - val_accuracy: 0.5917\n",
            "Epoch 16/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4642 - val_loss: 0.8640 - val_accuracy: 0.5941\n",
            "Epoch 17/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4661 - val_loss: 0.8661 - val_accuracy: 0.5953\n",
            "Epoch 18/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4662 - val_loss: 0.8590 - val_accuracy: 0.5953\n",
            "Epoch 19/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4651 - val_loss: 0.8574 - val_accuracy: 0.5989\n",
            "Epoch 20/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4679 - val_loss: 0.8572 - val_accuracy: 0.5988\n",
            "Epoch 21/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4676 - val_loss: 0.8569 - val_accuracy: 0.6004\n",
            "Epoch 22/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4692 - val_loss: 0.8513 - val_accuracy: 0.6041\n",
            "Epoch 23/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4720 - val_loss: 0.8575 - val_accuracy: 0.6015\n",
            "Epoch 24/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4670 - val_loss: 0.8465 - val_accuracy: 0.6077\n",
            "Epoch 25/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4721 - val_loss: 0.8493 - val_accuracy: 0.6051\n",
            "Epoch 26/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4743 - val_loss: 0.8468 - val_accuracy: 0.6085\n",
            "Epoch 27/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4728 - val_loss: 0.8424 - val_accuracy: 0.6098\n",
            "Epoch 28/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4737 - val_loss: 0.8403 - val_accuracy: 0.6115\n",
            "Epoch 29/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4719 - val_loss: 0.8397 - val_accuracy: 0.6103\n",
            "Epoch 30/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4734 - val_loss: 0.8395 - val_accuracy: 0.6115\n",
            "Epoch 31/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4759 - val_loss: 0.8385 - val_accuracy: 0.6133\n",
            "Epoch 32/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4740 - val_loss: 0.8351 - val_accuracy: 0.6159\n",
            "Epoch 33/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4734 - val_loss: 0.8473 - val_accuracy: 0.6093\n",
            "Epoch 34/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4756 - val_loss: 0.8339 - val_accuracy: 0.6163\n",
            "Epoch 35/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4763 - val_loss: 0.8370 - val_accuracy: 0.6116\n",
            "Epoch 36/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4766 - val_loss: 0.8339 - val_accuracy: 0.6140\n",
            "Epoch 37/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4804 - val_loss: 0.8340 - val_accuracy: 0.6157\n",
            "Epoch 38/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4794 - val_loss: 0.8330 - val_accuracy: 0.6166\n",
            "Epoch 39/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4781 - val_loss: 0.8320 - val_accuracy: 0.6160\n",
            "Epoch 40/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4790 - val_loss: 0.8307 - val_accuracy: 0.6139\n",
            "Epoch 41/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4851 - val_loss: 0.8334 - val_accuracy: 0.6146\n",
            "Epoch 42/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4751 - val_loss: 0.8331 - val_accuracy: 0.6124\n",
            "Epoch 43/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4788 - val_loss: 0.8275 - val_accuracy: 0.6208\n",
            "Epoch 44/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4853 - val_loss: 0.8273 - val_accuracy: 0.6188\n",
            "Epoch 45/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4810 - val_loss: 0.8269 - val_accuracy: 0.6207\n",
            "Epoch 46/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4834 - val_loss: 0.8295 - val_accuracy: 0.6156\n",
            "Epoch 47/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4816 - val_loss: 0.8252 - val_accuracy: 0.6214\n",
            "Epoch 48/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4850 - val_loss: 0.8291 - val_accuracy: 0.6172\n",
            "Epoch 49/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4815 - val_loss: 0.8256 - val_accuracy: 0.6206\n",
            "Epoch 50/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4848 - val_loss: 0.8245 - val_accuracy: 0.6192\n",
            "Epoch 51/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4869 - val_loss: 0.8247 - val_accuracy: 0.6217\n",
            "Epoch 52/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4847 - val_loss: 0.8258 - val_accuracy: 0.6227\n",
            "Epoch 53/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4854 - val_loss: 0.8245 - val_accuracy: 0.6209\n",
            "Epoch 54/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4871 - val_loss: 0.8247 - val_accuracy: 0.6223\n",
            "Epoch 55/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4882 - val_loss: 0.8346 - val_accuracy: 0.6186\n",
            "Epoch 56/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4891 - val_loss: 0.8307 - val_accuracy: 0.6150\n",
            "Epoch 57/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4866 - val_loss: 0.8260 - val_accuracy: 0.6203\n",
            "Epoch 58/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4885 - val_loss: 0.8309 - val_accuracy: 0.6183\n",
            "Epoch 59/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4851 - val_loss: 0.8246 - val_accuracy: 0.6213\n",
            "Epoch 60/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4874 - val_loss: 0.8269 - val_accuracy: 0.6201\n",
            "Epoch 61/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4920 - val_loss: 0.8279 - val_accuracy: 0.6205\n",
            "Epoch 62/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4891 - val_loss: 0.8441 - val_accuracy: 0.6108\n",
            "Epoch 63/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4912 - val_loss: 0.8414 - val_accuracy: 0.6121\n",
            "Epoch 64/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4875 - val_loss: 0.8261 - val_accuracy: 0.6162\n",
            "Epoch 65/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4887 - val_loss: 0.8328 - val_accuracy: 0.6171\n",
            "Epoch 66/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4891 - val_loss: 0.8337 - val_accuracy: 0.6183\n",
            "Epoch 67/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4911 - val_loss: 0.8329 - val_accuracy: 0.6170\n",
            "Epoch 68/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4894 - val_loss: 0.8260 - val_accuracy: 0.6198\n",
            "Epoch 69/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4918 - val_loss: 0.8287 - val_accuracy: 0.6173\n",
            "Epoch 70/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4903 - val_loss: 0.8294 - val_accuracy: 0.6169\n",
            "Epoch 71/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4928 - val_loss: 0.8367 - val_accuracy: 0.6168\n",
            "Epoch 72/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4928 - val_loss: 0.8555 - val_accuracy: 0.6084\n",
            "Epoch 73/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4945 - val_loss: 0.8318 - val_accuracy: 0.6216\n",
            "Epoch 74/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4953 - val_loss: 0.8331 - val_accuracy: 0.6212\n",
            "Epoch 75/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4915 - val_loss: 0.8287 - val_accuracy: 0.6189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GC9N25nZeGw5"
      },
      "id": "GC9N25nZeGw5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re4 = model.evaluate(test_tensor, y_test_onehot)\n",
        "print('Accuracy for 5b GRU  is ' , re4[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqqaRMN1cJw9",
        "outputId": "b24733af-d1ac-4e1b-9c66-a3d6ade9f453"
      },
      "id": "KqqaRMN1cJw9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8286 - accuracy: 0.6189\n",
            "Accuracy for 5b GRU  is  0.6189166903495789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5c) LSTM"
      ],
      "metadata": {
        "id": "COw9xvEod3tA"
      },
      "id": "COw9xvEod3tA"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, SimpleRNN, Bidirectional, GRU, LSTM\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(train_tensor.shape[1],train_tensor.shape[2])))\n",
        "# model.add(Flatten())\n",
        "# model.add(Embedding(train_tensor.shape[0], 300, input_length = 20))\n",
        "model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(10, activation = 'relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.add(Dropout(0.4))\n",
        "# model.build(input_shape=X_train_w2v_first20.shape)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cOqH0and-iA",
        "outputId": "04a17cfa-564a-4a90-99b1-f21cdb253844"
      },
      "id": "6cOqH0and-iA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 20, 40)           51360     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 3)                 2403      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,763\n",
            "Trainable params: 53,763\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_results_5C = model.fit(train_tensor, \n",
        "                             y_train_onehot, \n",
        "                             epochs=75, \n",
        "                             batch_size=50, \n",
        "                            \n",
        "                             validation_data=(test_tensor, y_test_onehot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9P5JF14eIlY",
        "outputId": "b179fa95-d442-4007-d4bd-2cc600ede63b"
      },
      "id": "K9P5JF14eIlY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "960/960 [==============================] - 10s 7ms/step - loss: nan - accuracy: 0.3942 - val_loss: 0.9712 - val_accuracy: 0.5293\n",
            "Epoch 2/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4339 - val_loss: 0.9320 - val_accuracy: 0.5509\n",
            "Epoch 3/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4436 - val_loss: 0.9179 - val_accuracy: 0.5627\n",
            "Epoch 4/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4458 - val_loss: 0.9047 - val_accuracy: 0.5723\n",
            "Epoch 5/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4484 - val_loss: 0.8953 - val_accuracy: 0.5799\n",
            "Epoch 6/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4532 - val_loss: 0.8948 - val_accuracy: 0.5810\n",
            "Epoch 7/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4514 - val_loss: 0.8824 - val_accuracy: 0.5869\n",
            "Epoch 8/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4580 - val_loss: 0.8837 - val_accuracy: 0.5857\n",
            "Epoch 9/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4618 - val_loss: 0.8742 - val_accuracy: 0.5935\n",
            "Epoch 10/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4595 - val_loss: 0.8696 - val_accuracy: 0.5937\n",
            "Epoch 11/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4591 - val_loss: 0.8658 - val_accuracy: 0.5957\n",
            "Epoch 12/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4632 - val_loss: 0.8672 - val_accuracy: 0.5942\n",
            "Epoch 13/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4646 - val_loss: 0.8658 - val_accuracy: 0.5966\n",
            "Epoch 14/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4621 - val_loss: 0.8614 - val_accuracy: 0.5953\n",
            "Epoch 15/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4634 - val_loss: 0.8616 - val_accuracy: 0.5980\n",
            "Epoch 16/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4647 - val_loss: 0.8537 - val_accuracy: 0.6013\n",
            "Epoch 17/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4666 - val_loss: 0.8537 - val_accuracy: 0.6032\n",
            "Epoch 18/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4692 - val_loss: 0.8492 - val_accuracy: 0.6063\n",
            "Epoch 19/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4719 - val_loss: 0.8507 - val_accuracy: 0.6047\n",
            "Epoch 20/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4671 - val_loss: 0.8484 - val_accuracy: 0.6054\n",
            "Epoch 21/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4645 - val_loss: 0.8460 - val_accuracy: 0.6023\n",
            "Epoch 22/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4687 - val_loss: 0.8445 - val_accuracy: 0.6043\n",
            "Epoch 23/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4691 - val_loss: 0.8421 - val_accuracy: 0.6074\n",
            "Epoch 24/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4670 - val_loss: 0.8430 - val_accuracy: 0.6083\n",
            "Epoch 25/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4710 - val_loss: 0.8391 - val_accuracy: 0.6096\n",
            "Epoch 26/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4706 - val_loss: 0.8375 - val_accuracy: 0.6106\n",
            "Epoch 27/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4691 - val_loss: 0.8363 - val_accuracy: 0.6141\n",
            "Epoch 28/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4750 - val_loss: 0.8399 - val_accuracy: 0.6051\n",
            "Epoch 29/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4739 - val_loss: 0.8323 - val_accuracy: 0.6133\n",
            "Epoch 30/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4741 - val_loss: 0.8301 - val_accuracy: 0.6144\n",
            "Epoch 31/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4767 - val_loss: 0.8319 - val_accuracy: 0.6143\n",
            "Epoch 32/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4806 - val_loss: 0.8328 - val_accuracy: 0.6136\n",
            "Epoch 33/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4741 - val_loss: 0.8286 - val_accuracy: 0.6141\n",
            "Epoch 34/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4742 - val_loss: 0.8291 - val_accuracy: 0.6143\n",
            "Epoch 35/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4772 - val_loss: 0.8292 - val_accuracy: 0.6152\n",
            "Epoch 36/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4791 - val_loss: 0.8279 - val_accuracy: 0.6168\n",
            "Epoch 37/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4779 - val_loss: 0.8231 - val_accuracy: 0.6158\n",
            "Epoch 38/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4814 - val_loss: 0.8230 - val_accuracy: 0.6172\n",
            "Epoch 39/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4799 - val_loss: 0.8246 - val_accuracy: 0.6156\n",
            "Epoch 40/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4833 - val_loss: 0.8268 - val_accuracy: 0.6150\n",
            "Epoch 41/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4863 - val_loss: 0.8247 - val_accuracy: 0.6141\n",
            "Epoch 42/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4808 - val_loss: 0.8240 - val_accuracy: 0.6166\n",
            "Epoch 43/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4825 - val_loss: 0.8209 - val_accuracy: 0.6223\n",
            "Epoch 44/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4817 - val_loss: 0.8248 - val_accuracy: 0.6209\n",
            "Epoch 45/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4832 - val_loss: 0.8220 - val_accuracy: 0.6189\n",
            "Epoch 46/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4839 - val_loss: 0.8312 - val_accuracy: 0.6142\n",
            "Epoch 47/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4841 - val_loss: 0.8215 - val_accuracy: 0.6231\n",
            "Epoch 48/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4869 - val_loss: 0.8235 - val_accuracy: 0.6145\n",
            "Epoch 49/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4874 - val_loss: 0.8234 - val_accuracy: 0.6200\n",
            "Epoch 50/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4875 - val_loss: 0.8230 - val_accuracy: 0.6210\n",
            "Epoch 51/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4852 - val_loss: 0.8360 - val_accuracy: 0.6174\n",
            "Epoch 52/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4864 - val_loss: 0.8485 - val_accuracy: 0.6131\n",
            "Epoch 53/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4870 - val_loss: 0.8216 - val_accuracy: 0.6191\n",
            "Epoch 54/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4861 - val_loss: 0.8226 - val_accuracy: 0.6217\n",
            "Epoch 55/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4836 - val_loss: 0.8214 - val_accuracy: 0.6208\n",
            "Epoch 56/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4877 - val_loss: 0.8262 - val_accuracy: 0.6177\n",
            "Epoch 57/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4896 - val_loss: 0.8242 - val_accuracy: 0.6235\n",
            "Epoch 58/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4921 - val_loss: 0.8206 - val_accuracy: 0.6202\n",
            "Epoch 59/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4912 - val_loss: 0.8281 - val_accuracy: 0.6166\n",
            "Epoch 60/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4856 - val_loss: 0.8203 - val_accuracy: 0.6170\n",
            "Epoch 61/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4890 - val_loss: 0.8220 - val_accuracy: 0.6201\n",
            "Epoch 62/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4887 - val_loss: 0.8232 - val_accuracy: 0.6231\n",
            "Epoch 63/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4880 - val_loss: 0.8267 - val_accuracy: 0.6201\n",
            "Epoch 64/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4923 - val_loss: 0.8237 - val_accuracy: 0.6199\n",
            "Epoch 65/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4969 - val_loss: 0.8369 - val_accuracy: 0.6138\n",
            "Epoch 66/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4963 - val_loss: 0.8320 - val_accuracy: 0.6166\n",
            "Epoch 67/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4957 - val_loss: 0.8306 - val_accuracy: 0.6156\n",
            "Epoch 68/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4910 - val_loss: 0.8219 - val_accuracy: 0.6232\n",
            "Epoch 69/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4941 - val_loss: 0.8339 - val_accuracy: 0.6137\n",
            "Epoch 70/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4927 - val_loss: 0.8314 - val_accuracy: 0.6113\n",
            "Epoch 71/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4927 - val_loss: 0.8277 - val_accuracy: 0.6218\n",
            "Epoch 72/75\n",
            "960/960 [==============================] - 7s 7ms/step - loss: nan - accuracy: 0.4937 - val_loss: 0.8275 - val_accuracy: 0.6230\n",
            "Epoch 73/75\n",
            "960/960 [==============================] - 6s 7ms/step - loss: nan - accuracy: 0.4964 - val_loss: 0.8301 - val_accuracy: 0.6216\n",
            "Epoch 74/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4950 - val_loss: 0.8258 - val_accuracy: 0.6182\n",
            "Epoch 75/75\n",
            "960/960 [==============================] - 6s 6ms/step - loss: nan - accuracy: 0.4955 - val_loss: 0.8265 - val_accuracy: 0.6214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re5 = model.evaluate(test_tensor, y_test_onehot)\n",
        "print('Accuracy for 5c LSTM  is ' , re5[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6qI_XupeSH1",
        "outputId": "3bba6111-8ca2-499f-e206-72d0ed3bbfee"
      },
      "id": "x6qI_XupeSH1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 3ms/step - loss: 0.8265 - accuracy: 0.6214\n",
            "Accuracy for 5b GRU  is  0.6214166879653931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: I conclude that GRU and LSTM layer has similar and high accuracy(62%) than any other models. Simple RNN modle has the least performance(58%)"
      ],
      "metadata": {
        "id": "8Ws6sNfwuAkv"
      },
      "id": "8Ws6sNfwuAkv"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R5vnvf8ceStD"
      },
      "id": "R5vnvf8ceStD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}